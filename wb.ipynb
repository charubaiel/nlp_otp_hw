{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/charubaiel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import lightgbm as lgbm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "nltk.download(\"stopwords\")\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pos \\ neg - комменты с твиттера http://study.mokoron.com/ \n",
    "# labeled каггловский датасет по токсикам https://www.kaggle.com/blackmoon/russian-language-toxic-comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_neg = pd.read_csv('data/negative.csv',sep=';',header=None,usecols=[3])\n",
    "twitter_pos = pd.read_csv('data/positive.csv',sep=';',header=None,usecols=[3])\n",
    "vk_all = pd.read_csv('data/labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl_toxic = vk_all.append(twitter_pos.rename(columns={3:'comment'}).sample(5000)).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.751391\n",
       "1.0    0.248609\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttl_toxic['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,val_data,target,val_target = model_selection.train_test_split(ttl_toxic['comment'],ttl_toxic['toxic'],train_size=.75,stratify=ttl_toxic['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stupid baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = feature_extraction.text.TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_base = linear_model.LogisticRegression(max_iter=1000,C=6,class_weight=target.value_counts().to_dict())\n",
    "pipe_base = pipeline.make_pipeline(tf,clf_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "[CV] END  f1: (test=0.692) precision: (test=0.780) recall: (test=0.622) total time=   9.7s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.677) precision: (test=0.748) recall: (test=0.619) total time=  12.4s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   22.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.682) precision: (test=0.730) recall: (test=0.641) total time=  14.4s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   36.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.698) precision: (test=0.770) recall: (test=0.638) total time=  11.1s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   47.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.669) precision: (test=0.746) recall: (test=0.606) total time=  16.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "scores['baseline'] = pd.DataFrame(model_selection.cross_validate(pipe_base,data,target,scoring=['f1','precision','recall'],cv=5,verbose=10)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>12.800853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.091049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.683593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.754707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.625029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 baseline\n",
       "fit_time        12.800853\n",
       "score_time       0.091049\n",
       "test_f1          0.683593\n",
       "test_precision   0.754707\n",
       "test_recall      0.625029"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charubaiel/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=6, class_weight={0.0: 10940, 1.0: 3619},\n",
       "                                    max_iter=1000))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_base.fit(data,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### work with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "stopwords = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer (text):\n",
    "    words_only = re.sub('[^А-я]+',' ',text.lower())\n",
    "    doc = Doc(words_only)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    clean_text = []\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "        if (token.lemma not in stopwords) & (len(set(token.lemma))>1):\n",
    "            clean_text.append(token.lemma)\n",
    "            \n",
    "    return ' '.join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data.copy()\n",
    "old_text = ' жожо '.join(data)\n",
    "new_text = normalizer(old_text)\n",
    "data = pd.Series(new_text.split('жожо'))\n",
    "raw_val_data = val_data.copy()\n",
    "val_data = pd.Series(normalizer(' жожо '.join(val_data)).split('жожо'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_norm = linear_model.LogisticRegression(max_iter=1000,C=6,class_weight= target.value_counts(normalize=True).to_dict())\n",
    "pipe_norm = pipeline.make_pipeline(tf,clf_norm)\n",
    "scores['normalize'] = pd.DataFrame(model_selection.cross_validate(pipe_norm,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=6,\n",
       "                                    class_weight={0.0: 0.7514252352496738,\n",
       "                                                  1.0: 0.24857476475032625},\n",
       "                                    max_iter=1000))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_norm.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>12.800853</td>\n",
       "      <td>0.653476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.091049</td>\n",
       "      <td>0.059086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.683593</td>\n",
       "      <td>0.441161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.754707</td>\n",
       "      <td>0.929528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.625029</td>\n",
       "      <td>0.289309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 baseline  normalize\n",
       "fit_time        12.800853   0.653476\n",
       "score_time       0.091049   0.059086\n",
       "test_f1          0.683593   0.441161\n",
       "test_precision   0.754707   0.929528\n",
       "test_recall      0.625029   0.289309"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### micro EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda = vk_all.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda['txt_len'] = eda['comment'].str.len()\n",
    "eda['txt_len_avg'] = eda['comment'].str.split().apply(lambda x: np.mean([len(word) for word in x]))\n",
    "eda['txt_words'] = eda['comment'].str.count(' ')\n",
    "eda['txt_puncts'] = eda['comment'].str.count('[^\\w^ ]')\n",
    "eda['txt_upper_cnt'] = eda['comment'].apply(lambda x: len([i for i in x if i.isupper()]))\n",
    "eda['txt_pct_upper'] = eda['txt_upper_cnt'] / eda['txt_len']\n",
    "eda['txt_pos_punc'] = eda['comment'].apply(lambda text: len(re.findall(r'\\)|D',text)))\n",
    "eda['txt_neg_punc'] = eda['comment'].apply(lambda text: len(re.findall(r'\\(|C|c|С|c',text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_len</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_len_avg</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_words</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_puncts</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_upper_cnt</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_pct_upper</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_pos_punc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_neg_punc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>194.213332</td>\n",
       "      <td>274.750067</td>\n",
       "      <td>5.312308</td>\n",
       "      <td>1.063207</td>\n",
       "      <td>29.713436</td>\n",
       "      <td>40.811415</td>\n",
       "      <td>7.481849</td>\n",
       "      <td>9.135183</td>\n",
       "      <td>3.984978</td>\n",
       "      <td>7.812980</td>\n",
       "      <td>0.023631</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>0.279261</td>\n",
       "      <td>0.709825</td>\n",
       "      <td>0.499478</td>\n",
       "      <td>1.353467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>141.392665</td>\n",
       "      <td>261.776417</td>\n",
       "      <td>5.467866</td>\n",
       "      <td>1.466984</td>\n",
       "      <td>21.449233</td>\n",
       "      <td>42.106635</td>\n",
       "      <td>5.972234</td>\n",
       "      <td>9.188326</td>\n",
       "      <td>6.595939</td>\n",
       "      <td>26.932055</td>\n",
       "      <td>0.052774</td>\n",
       "      <td>0.130923</td>\n",
       "      <td>0.094488</td>\n",
       "      <td>0.434023</td>\n",
       "      <td>0.454414</td>\n",
       "      <td>1.689128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          txt_len             txt_len_avg            txt_words             \\\n",
       "             mean         std        mean       std       mean        std   \n",
       "toxic                                                                       \n",
       "0.0    194.213332  274.750067    5.312308  1.063207  29.713436  40.811415   \n",
       "1.0    141.392665  261.776417    5.467866  1.466984  21.449233  42.106635   \n",
       "\n",
       "      txt_puncts           txt_upper_cnt            txt_pct_upper            \\\n",
       "            mean       std          mean        std          mean       std   \n",
       "toxic                                                                         \n",
       "0.0     7.481849  9.135183      3.984978   7.812980      0.023631  0.027502   \n",
       "1.0     5.972234  9.188326      6.595939  26.932055      0.052774  0.130923   \n",
       "\n",
       "      txt_pos_punc           txt_neg_punc            \n",
       "              mean       std         mean       std  \n",
       "toxic                                                \n",
       "0.0       0.279261  0.709825     0.499478  1.353467  \n",
       "1.0       0.094488  0.434023     0.454414  1.689128  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.groupby('toxic')[eda.filter(regex='txt').columns].agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>txt_len</th>\n",
       "      <th>txt_len_avg</th>\n",
       "      <th>txt_words</th>\n",
       "      <th>txt_puncts</th>\n",
       "      <th>txt_upper_cnt</th>\n",
       "      <th>txt_pct_upper</th>\n",
       "      <th>txt_pos_punc</th>\n",
       "      <th>txt_neg_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091782</td>\n",
       "      <td>0.060394</td>\n",
       "      <td>-0.094138</td>\n",
       "      <td>-0.077608</td>\n",
       "      <td>0.072997</td>\n",
       "      <td>0.171514</td>\n",
       "      <td>-0.136895</td>\n",
       "      <td>-0.014424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_len</th>\n",
       "      <td>-0.091782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024703</td>\n",
       "      <td>0.991756</td>\n",
       "      <td>0.924170</td>\n",
       "      <td>0.370052</td>\n",
       "      <td>-0.047513</td>\n",
       "      <td>0.382291</td>\n",
       "      <td>0.529863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_len_avg</th>\n",
       "      <td>0.060394</td>\n",
       "      <td>0.024703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025150</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.022158</td>\n",
       "      <td>0.079450</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>0.037176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_words</th>\n",
       "      <td>-0.094138</td>\n",
       "      <td>0.991756</td>\n",
       "      <td>-0.025150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929034</td>\n",
       "      <td>0.368631</td>\n",
       "      <td>-0.049015</td>\n",
       "      <td>0.378389</td>\n",
       "      <td>0.514993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_puncts</th>\n",
       "      <td>-0.077608</td>\n",
       "      <td>0.924170</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.929034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346096</td>\n",
       "      <td>-0.033393</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.497885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_upper_cnt</th>\n",
       "      <td>0.072997</td>\n",
       "      <td>0.370052</td>\n",
       "      <td>0.022158</td>\n",
       "      <td>0.368631</td>\n",
       "      <td>0.346096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565105</td>\n",
       "      <td>0.115176</td>\n",
       "      <td>0.692265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_pct_upper</th>\n",
       "      <td>0.171514</td>\n",
       "      <td>-0.047513</td>\n",
       "      <td>0.079450</td>\n",
       "      <td>-0.049015</td>\n",
       "      <td>-0.033393</td>\n",
       "      <td>0.565105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040094</td>\n",
       "      <td>0.312005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_pos_punc</th>\n",
       "      <td>-0.136895</td>\n",
       "      <td>0.382291</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>0.378389</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.115176</td>\n",
       "      <td>-0.040094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.395420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_neg_punc</th>\n",
       "      <td>-0.014424</td>\n",
       "      <td>0.529863</td>\n",
       "      <td>0.037176</td>\n",
       "      <td>0.514993</td>\n",
       "      <td>0.497885</td>\n",
       "      <td>0.692265</td>\n",
       "      <td>0.312005</td>\n",
       "      <td>0.395420</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  toxic   txt_len  txt_len_avg  txt_words  txt_puncts  \\\n",
       "toxic          1.000000 -0.091782     0.060394  -0.094138   -0.077608   \n",
       "txt_len       -0.091782  1.000000     0.024703   0.991756    0.924170   \n",
       "txt_len_avg    0.060394  0.024703     1.000000  -0.025150    0.016616   \n",
       "txt_words     -0.094138  0.991756    -0.025150   1.000000    0.929034   \n",
       "txt_puncts    -0.077608  0.924170     0.016616   0.929034    1.000000   \n",
       "txt_upper_cnt  0.072997  0.370052     0.022158   0.368631    0.346096   \n",
       "txt_pct_upper  0.171514 -0.047513     0.079450  -0.049015   -0.033393   \n",
       "txt_pos_punc  -0.136895  0.382291    -0.001665   0.378389    0.418016   \n",
       "txt_neg_punc  -0.014424  0.529863     0.037176   0.514993    0.497885   \n",
       "\n",
       "               txt_upper_cnt  txt_pct_upper  txt_pos_punc  txt_neg_punc  \n",
       "toxic               0.072997       0.171514     -0.136895     -0.014424  \n",
       "txt_len             0.370052      -0.047513      0.382291      0.529863  \n",
       "txt_len_avg         0.022158       0.079450     -0.001665      0.037176  \n",
       "txt_words           0.368631      -0.049015      0.378389      0.514993  \n",
       "txt_puncts          0.346096      -0.033393      0.418016      0.497885  \n",
       "txt_upper_cnt       1.000000       0.565105      0.115176      0.692265  \n",
       "txt_pct_upper       0.565105       1.000000     -0.040094      0.312005  \n",
       "txt_pos_punc        0.115176      -0.040094      1.000000      0.395420  \n",
       "txt_neg_punc        0.692265       0.312005      0.395420      1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.iloc[:,1:].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_from_text(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns=['text']\n",
    "    df['txt_len'] = df['text'].str.len()\n",
    "    df['txt_len_avg'] = df['text'].str.split().apply(lambda x: np.mean([len(word) for word in x]))\n",
    "    df['txt_words'] = df['text'].str.count(' ')\n",
    "    df['txt_puncts'] = df['text'].str.count('[^\\w^ ]')\n",
    "    df['txt_upper_cnt'] = df['text'].apply(lambda x: len([i for i in x if i.isupper()]))\n",
    "    df['txt_pos_punc'] = df['text'].apply(lambda text: len(re.findall(r'\\)|D',text)))\n",
    "    df['txt_neg_punc'] = df['text'].apply(lambda text: len(re.findall(r'\\(|C|c|С|c',text)))\n",
    "    \n",
    "    return df.drop('text',axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_tf = feature_extraction.text.TfidfVectorizer()\n",
    "fe_tf.fit(data,target)\n",
    "new_fe=preprocessing.FunctionTransformer(features_from_text)\n",
    "text_preproc = pipeline.FeatureUnion([('idf',fe_tf),('fe',new_fe)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_fe = linear_model.LogisticRegression(max_iter=1000,C=6,class_weight= target.value_counts().to_dict())\n",
    "pipe_fe = pipeline.Pipeline([('preproc',text_preproc),('clf',clf_fe)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "scores['features'] = pd.DataFrame(model_selection.cross_validate(pipe_fe,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preproc',\n",
       "                 FeatureUnion(transformer_list=[('idf', TfidfVectorizer()),\n",
       "                                                ('fe',\n",
       "                                                 FunctionTransformer(func=<function features_from_text at 0x7f0c26d025e0>))])),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=6, class_weight={0.0: 10940, 1.0: 3619},\n",
       "                                    max_iter=1000))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_fe.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>12.800853</td>\n",
       "      <td>0.653476</td>\n",
       "      <td>9.701039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.091049</td>\n",
       "      <td>0.059086</td>\n",
       "      <td>0.137960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.683593</td>\n",
       "      <td>0.441161</td>\n",
       "      <td>0.708981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.754707</td>\n",
       "      <td>0.929528</td>\n",
       "      <td>0.756540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.625029</td>\n",
       "      <td>0.289309</td>\n",
       "      <td>0.667313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 baseline  normalize  features\n",
       "fit_time        12.800853   0.653476  9.701039\n",
       "score_time       0.091049   0.059086  0.137960\n",
       "test_f1          0.683593   0.441161  0.708981\n",
       "test_precision   0.754707   0.929528  0.756540\n",
       "test_recall      0.625029   0.289309  0.667313"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav = Navec.load('models/emb_navec.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vecror(sentence_list):\n",
    "    vectors = []\n",
    "    for sentence in sentence_list:\n",
    "        sent_vec = []\n",
    "        for i in sentence.split():\n",
    "            if i in nav:\n",
    "                sent_vec.append(nav[i])\n",
    "            else:\n",
    "                sent_vec.append(nav['<unk>'])\n",
    "        if sentence.strip() == '':\n",
    "            sent_vec = [nav['<unk>']]\n",
    "        vectors.append(np.mean(sent_vec,axis=0))\n",
    "    return np.vstack(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_func = preprocessing.FunctionTransformer(get_sentence_vecror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_vec = linear_model.LogisticRegression(max_iter=1000,C=6,class_weight= target.value_counts().to_dict())\n",
    "pipe_vec = pipeline.make_pipeline(vec_func,clf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['sample_vec'] = pd.DataFrame(model_selection.cross_validate(pipe_vec,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_vec.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer = feature_extraction.text.TfidfVectorizer()\n",
    "word_vectorizer.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', min_df=3, ngram_range=(2, 4),\n",
       "                sublinear_tf=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vectorizer = feature_extraction.text.TfidfVectorizer(\n",
    "    min_df=3,\n",
    "    sublinear_tf=True,\n",
    "    analyzer='char',\n",
    "    ngram_range=(2,4))\n",
    "char_vectorizer.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_fu = pipeline.FeatureUnion([('idf_w',word_vectorizer),('idf_c',char_vectorizer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2idf = linear_model.LogisticRegression(max_iter=1000,C=6,class_weight= target.value_counts(normalize=True).to_dict())\n",
    "pipe_idf_fe = pipeline.Pipeline([('idf',idf_fu),('clf',clf_2idf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['idf_features'] = pd.DataFrame(model_selection.cross_validate(pipe_idf_fe,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('idf',\n",
       "                 TfidfVectorizer(analyzer='char', min_df=3, ngram_range=(2, 4),\n",
       "                                 sublinear_tf=True)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=6,\n",
       "                                    class_weight={0.0: 0.7514252352496738,\n",
       "                                                  1.0: 0.24857476475032625},\n",
       "                                    max_iter=1000))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_idf_fe.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_features</th>\n",
       "      <th>char_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>4.217547</td>\n",
       "      <td>2.552681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.447093</td>\n",
       "      <td>0.371240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.620917</td>\n",
       "      <td>0.557309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.937239</td>\n",
       "      <td>0.949638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.464488</td>\n",
       "      <td>0.394579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                idf_features  char_features\n",
       "fit_time            4.217547       2.552681\n",
       "score_time          0.447093       0.371240\n",
       "test_f1             0.620917       0.557309\n",
       "test_precision      0.937239       0.949638\n",
       "test_recall         0.464488       0.394579"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blend models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_func = preprocessing.FunctionTransformer(get_sentence_vecror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prior=target.value_counts(normalize=True).values[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_vec = linear_model.LogisticRegression(max_iter=1000,C=6,class_weight= target.value_counts().to_dict())\n",
    "clf_nb_vec = naive_bayes.BernoulliNB(class_prior=class_prior)\n",
    "clf_knn_vec = neighbors.KNeighborsClassifier(30)\n",
    "clf_svc_vec = linear_model.SGDClassifier(loss='modified_huber',class_weight= target.value_counts().to_dict())\n",
    "clf_rf_vec = lgbm.LGBMClassifier(n_estimators=1500,learning_rate=0.07,num_leaves=15,class_weight= target.value_counts().to_dict())\n",
    "clf_mlp_vec = neural_network.MLPClassifier(hidden_layer_sizes=(300,1),max_iter=1000,learning_rate='adaptive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for n,model in tqdm(enumerate([clf_lr_vec,clf_nb_vec,clf_knn_vec,clf_svc_vec,clf_rf_vec,clf_mlp_vec])):\n",
    "    tmp_pipe = pipeline.make_pipeline(vec_func,model)\n",
    "    models[n] = pd.DataFrame(model_selection.cross_validate(tmp_pipe,data,target,scoring=['f1','precision','recall'],cv=5)).mean()\n",
    "    print(models[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(models).rename(columns = {0:'lr',1:'nb',2:'knn',3:'svc',4:'gbm',5:'mlp'}).T.sort_values(by='test_f1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vote_vec = ensemble.VotingClassifier(estimators=[('lr',clf_lr_vec),('svc',clf_svc_vec),('gbm',clf_rf_vec),('mlp',clf_mlp_vec)],voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_vote_vec = pipeline.make_pipeline(vec_func,vote_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['vote_models'] = pd.DataFrame(model_selection.cross_validate(pipe_vote_vec,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_vote_vec.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blend results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(estimators,x,func=np.mean):\n",
    "    probs = []\n",
    "    for i in estimators:\n",
    "        probs.append(i.predict_proba(x)[:,1])\n",
    "    return np.apply_over_axes(func,np.array(probs),axes=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = defaultdict(list)\n",
    "for model in [pipe_norm,pipe_fe,pipe_idf_fe,pipe_vec,pipe_vote_vec]:\n",
    "    eval_data['f1'].append(metrics.f1_score(val_target,model.predict(val_data)))\n",
    "    eval_data['recall'].append(metrics.recall_score(val_target,model.predict(val_data)))\n",
    "    eval_data['precision'].append(metrics.precision_score(val_target,model.predict(val_data)))\n",
    "    eval_data['roc_auc'].append(metrics.roc_auc_score(val_target,model.predict(val_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data['f1'].append(metrics.f1_score(val_target,voting([pipe_vec,pipe_idf_fe,pipe_vote_vec],val_data).round()))\n",
    "eval_data['recall'].append(metrics.recall_score(val_target,voting([pipe_vec,pipe_idf_fe,pipe_vote_vec],val_data).round()))\n",
    "eval_data['precision'].append(metrics.precision_score(val_target,voting([pipe_vec,pipe_idf_fe,pipe_vote_vec],val_data).round()))\n",
    "eval_data['roc_auc'].append(metrics.roc_auc_score(val_target,voting([pipe_vec,pipe_idf_fe,pipe_vote_vec],val_data).round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data['f1'].append(metrics.f1_score(val_target,voting([pipe_vec,pipe_idf_fe,pipe_vote_vec],val_data,func=np.max).round()))\n",
    "eval_data['recall'].append(metrics.recall_score(val_target,voting([pipe_vec,pipe_idf_fe,pipe_vote_vec],val_data,func=np.max).round()))\n",
    "eval_data['precision'].append(metrics.precision_score(val_target,voting([pipe_vec,pipe_idf_fe,pipe_vote_vec],val_data,func=np.max).round()))\n",
    "eval_data['roc_auc'].append(metrics.roc_auc_score(val_target,voting([pipe_vec,pipe_idf_fe,pipe_vote_vec],val_data,func=np.max).round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(eval_data,index=['norm','fe','idf_df','vec','vote_vec','blend_mean','blend_max']).sort_values(by='f1',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_text (text):\n",
    "    return pd.Series({'pure_idf_model' : pipe_norm.predict_proba([text])[:,1][0],\n",
    "    'some_features_model' : pipe_fe.predict_proba([text])[:,1][0],\n",
    "    'double_idf_model' :pipe_idf_fe.predict_proba([text])[:,1][0],\n",
    "    'pure_vectors_model' :pipe_vec.predict_proba([text])[:,1][0],\n",
    "    'blending_models' : pipe_vote_vec.predict_proba([text])[:,1][0],\n",
    "    'blending_ttl_mean' : voting([pipe_vec,pipe_idf_fe],[text],func=np.mean)[0],\n",
    "    'blending_ttl_max' : voting([pipe_vec,pipe_idf_fe],[text],func=np.max)[0]},name='Степень токсичности')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_predict(model,text):\n",
    "    return model.predict_proba([text])[:,1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "time_predict(pipe_norm,'Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "time_predict(pipe_fe,'Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "time_predict(pipe_idf_fe,'Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "time_predict(pipe_vec,'Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "time_predict(pipe_vote_vec,'Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "check_text('Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_text('Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал').to_frame().style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipe_vec,'models/model_vec_2.joblib')\n",
    "joblib.dump(pipe_idf_fe,'models/model_idf_2.joblib')\n",
    "joblib.dump(pipe_vote_vec,'models/model_vec_vote_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7801a1fce19b4dbca8b7bce4059e552648312323ed9d108616a9100a6d7a4a9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
