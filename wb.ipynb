{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Charubaiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pos \\ neg - комменты с твиттера http://study.mokoron.com/\n",
    "# labeled каггловский датасет по токсикам https://www.kaggle.com/blackmoon/russian-language-toxic-comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_neg = pd.read_csv('data/negative.csv',sep=';',header=None,usecols=[3])\n",
    "twitter_pos = pd.read_csv('data/positive.csv',sep=';',header=None,usecols=[3])\n",
    "vk_all = pd.read_csv('data/labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl_toxic = vk_all.append(twitter_neg.rename(columns={3:'comment'})).fillna(1)\n",
    "df = ttl_toxic.append(twitter_pos.rename(columns={3:'comment'})).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.516058\n",
       "1.0    0.483942\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stupid baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = feature_extraction.text.TfidfVectorizer(min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(min_df=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fit(vk_all['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression()\n",
    "pipe = pipeline.make_pipeline(tf,logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['baseline'] = pd.DataFrame(model_selection.cross_validate(pipe,vk_all['comment'],vk_all['toxic'],scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.378491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.069566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.694865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.872140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.594260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline\n",
       "fit_time        0.378491\n",
       "score_time      0.069566\n",
       "test_f1         0.694865\n",
       "test_precision  0.872140\n",
       "test_recall     0.594260"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### micro EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda = vk_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda['txt_len'] = eda['comment'].str.len()\n",
    "eda['txt_len_avg'] = eda['comment'].str.split().apply(lambda x: np.mean([len(word) for word in x]))\n",
    "eda['txt_words'] = eda['comment'].str.count(' ')\n",
    "eda['txt_puncts'] = eda['comment'].str.count('[^\\w^ ]')\n",
    "eda['txt_upper_cnt'] = eda['comment'].apply(lambda x: len([i for i in x if i.isupper()]))\n",
    "eda['txt_pos_punc'] = eda['comment'].apply(lambda text: len(re.findall(r'\\)|D',text)))\n",
    "eda['txt_neg_punc'] = eda['comment'].apply(lambda text: len(re.findall(r'\\(|C|c|С|c',text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_len</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_len_avg</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_words</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_puncts</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_upper_cnt</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_pos_punc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_neg_punc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>194.213332</td>\n",
       "      <td>274.750067</td>\n",
       "      <td>5.312308</td>\n",
       "      <td>1.063207</td>\n",
       "      <td>29.713436</td>\n",
       "      <td>40.811415</td>\n",
       "      <td>7.481849</td>\n",
       "      <td>9.135183</td>\n",
       "      <td>3.984978</td>\n",
       "      <td>7.812980</td>\n",
       "      <td>0.279261</td>\n",
       "      <td>0.709825</td>\n",
       "      <td>0.499478</td>\n",
       "      <td>1.353467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>141.392665</td>\n",
       "      <td>261.776417</td>\n",
       "      <td>5.467866</td>\n",
       "      <td>1.466984</td>\n",
       "      <td>21.449233</td>\n",
       "      <td>42.106635</td>\n",
       "      <td>5.972234</td>\n",
       "      <td>9.188326</td>\n",
       "      <td>6.595939</td>\n",
       "      <td>26.932055</td>\n",
       "      <td>0.094488</td>\n",
       "      <td>0.434023</td>\n",
       "      <td>0.454414</td>\n",
       "      <td>1.689128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          txt_len             txt_len_avg            txt_words             \\\n",
       "             mean         std        mean       std       mean        std   \n",
       "toxic                                                                       \n",
       "0.0    194.213332  274.750067    5.312308  1.063207  29.713436  40.811415   \n",
       "1.0    141.392665  261.776417    5.467866  1.466984  21.449233  42.106635   \n",
       "\n",
       "      txt_puncts           txt_upper_cnt            txt_pos_punc            \\\n",
       "            mean       std          mean        std         mean       std   \n",
       "toxic                                                                        \n",
       "0.0     7.481849  9.135183      3.984978   7.812980     0.279261  0.709825   \n",
       "1.0     5.972234  9.188326      6.595939  26.932055     0.094488  0.434023   \n",
       "\n",
       "      txt_neg_punc            \n",
       "              mean       std  \n",
       "toxic                         \n",
       "0.0       0.499478  1.353467  \n",
       "1.0       0.454414  1.689128  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.groupby('toxic')[eda.filter(regex='txt').columns].agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>txt_len</th>\n",
       "      <th>txt_len_avg</th>\n",
       "      <th>txt_words</th>\n",
       "      <th>txt_puncts</th>\n",
       "      <th>txt_upper_cnt</th>\n",
       "      <th>txt_pos_punc</th>\n",
       "      <th>txt_neg_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091782</td>\n",
       "      <td>0.060394</td>\n",
       "      <td>-0.094138</td>\n",
       "      <td>-0.077608</td>\n",
       "      <td>0.072997</td>\n",
       "      <td>-0.136895</td>\n",
       "      <td>-0.014424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_len</th>\n",
       "      <td>-0.091782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024703</td>\n",
       "      <td>0.991756</td>\n",
       "      <td>0.924170</td>\n",
       "      <td>0.370052</td>\n",
       "      <td>0.382291</td>\n",
       "      <td>0.529863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_len_avg</th>\n",
       "      <td>0.060394</td>\n",
       "      <td>0.024703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025150</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.022158</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>0.037176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_words</th>\n",
       "      <td>-0.094138</td>\n",
       "      <td>0.991756</td>\n",
       "      <td>-0.025150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929034</td>\n",
       "      <td>0.368631</td>\n",
       "      <td>0.378389</td>\n",
       "      <td>0.514993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_puncts</th>\n",
       "      <td>-0.077608</td>\n",
       "      <td>0.924170</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.929034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346096</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.497885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_upper_cnt</th>\n",
       "      <td>0.072997</td>\n",
       "      <td>0.370052</td>\n",
       "      <td>0.022158</td>\n",
       "      <td>0.368631</td>\n",
       "      <td>0.346096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115176</td>\n",
       "      <td>0.692265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_pos_punc</th>\n",
       "      <td>-0.136895</td>\n",
       "      <td>0.382291</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>0.378389</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.115176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.395420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_neg_punc</th>\n",
       "      <td>-0.014424</td>\n",
       "      <td>0.529863</td>\n",
       "      <td>0.037176</td>\n",
       "      <td>0.514993</td>\n",
       "      <td>0.497885</td>\n",
       "      <td>0.692265</td>\n",
       "      <td>0.395420</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  toxic   txt_len  txt_len_avg  txt_words  txt_puncts  \\\n",
       "toxic          1.000000 -0.091782     0.060394  -0.094138   -0.077608   \n",
       "txt_len       -0.091782  1.000000     0.024703   0.991756    0.924170   \n",
       "txt_len_avg    0.060394  0.024703     1.000000  -0.025150    0.016616   \n",
       "txt_words     -0.094138  0.991756    -0.025150   1.000000    0.929034   \n",
       "txt_puncts    -0.077608  0.924170     0.016616   0.929034    1.000000   \n",
       "txt_upper_cnt  0.072997  0.370052     0.022158   0.368631    0.346096   \n",
       "txt_pos_punc  -0.136895  0.382291    -0.001665   0.378389    0.418016   \n",
       "txt_neg_punc  -0.014424  0.529863     0.037176   0.514993    0.497885   \n",
       "\n",
       "               txt_upper_cnt  txt_pos_punc  txt_neg_punc  \n",
       "toxic               0.072997     -0.136895     -0.014424  \n",
       "txt_len             0.370052      0.382291      0.529863  \n",
       "txt_len_avg         0.022158     -0.001665      0.037176  \n",
       "txt_words           0.368631      0.378389      0.514993  \n",
       "txt_puncts          0.346096      0.418016      0.497885  \n",
       "txt_upper_cnt       1.000000      0.115176      0.692265  \n",
       "txt_pos_punc        0.115176      1.000000      0.395420  \n",
       "txt_neg_punc        0.692265      0.395420      1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.iloc[:,1:].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### work with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "stopwords = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vk_all['no_punct'] = vk_all['comment'].apply(lambda x: re.sub('\\W',' ',x).replace('  ',' ').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer (text):\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    clean_text = []\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "        if token.lemma not in stopwords:\n",
    "            clean_text.append(token.lemma)\n",
    "    return ' '.join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '|||'.join(vk_all['no_punct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = normalizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vk_all['normalize_text'] = new_text.split('| | |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['normalize'] = pd.DataFrame(model_selection.cross_validate(pipe,vk_all['normalize_text'],vk_all['toxic'],scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.378491</td>\n",
       "      <td>0.325110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.069566</td>\n",
       "      <td>0.051616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.694865</td>\n",
       "      <td>0.725498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.872140</td>\n",
       "      <td>0.894935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.594260</td>\n",
       "      <td>0.622248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize\n",
       "fit_time        0.378491   0.325110\n",
       "score_time      0.069566   0.051616\n",
       "test_f1         0.694865   0.725498\n",
       "test_precision  0.872140   0.894935\n",
       "test_recall     0.594260   0.622248"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_from_text(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns=['text']\n",
    "    df['txt_len'] = df['text'].str.len()\n",
    "    df['txt_len_avg'] = df['text'].str.split().apply(lambda x: np.mean([len(word) for word in x]))\n",
    "    df['txt_words'] = df['text'].str.count(' ')\n",
    "    df['txt_puncts'] = df['text'].str.count('[^\\w^ ]')\n",
    "    df['txt_upper_cnt'] = df['text'].apply(lambda x: len([i for i in x if i.isupper()]))\n",
    "    df['txt_pos_punc'] = df['text'].apply(lambda text: len(re.findall(r'\\)|D',text)))\n",
    "    df['txt_neg_punc'] = df['text'].apply(lambda text: len(re.findall(r'\\(|C|c|С|c',text)))\n",
    "    \n",
    "    return df.drop('text',axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fe=preprocessing.FunctionTransformer(features_from_text)\n",
    "fu = pipeline.FeatureUnion([('idf',tf),('fe',new_fe)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression()\n",
    "pipe_fe = pipeline.Pipeline([('fu',fu),('clf',clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['features'] = pd.DataFrame(model_selection.cross_validate(pipe_fe,vk_all['normalize_text'],vk_all['toxic'],scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.378491</td>\n",
       "      <td>0.325110</td>\n",
       "      <td>0.735161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.069566</td>\n",
       "      <td>0.051616</td>\n",
       "      <td>0.173052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.694865</td>\n",
       "      <td>0.725498</td>\n",
       "      <td>0.706075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.872140</td>\n",
       "      <td>0.894935</td>\n",
       "      <td>0.887883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.594260</td>\n",
       "      <td>0.622248</td>\n",
       "      <td>0.597176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize  features\n",
       "fit_time        0.378491   0.325110  0.735161\n",
       "score_time      0.069566   0.051616  0.173052\n",
       "test_f1         0.694865   0.725498  0.706075\n",
       "test_precision  0.872140   0.894935  0.887883\n",
       "test_recall     0.594260   0.622248  0.597176"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav = Navec.load('emb_navec.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vecror(sentence):\n",
    "    sent_vec = []\n",
    "    for i in sentence.split():\n",
    "        if i in nav:\n",
    "            sent_vec.append(nav[i])\n",
    "        else:\n",
    "            sent_vec.append(nav['<unk>'])\n",
    "    if sentence.strip() == '':\n",
    "        sent_vec = [nav['<unk>']]\n",
    "    return np.mean(sent_vec,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vk_vectors = np.vstack(vk_all['normalize_text'].apply(get_sentence_vecror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['sample_vec'] = pd.DataFrame(model_selection.cross_validate(logreg,vk_vectors,vk_all['toxic'],scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "      <th>features</th>\n",
       "      <th>sample_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.378491</td>\n",
       "      <td>0.325110</td>\n",
       "      <td>0.735161</td>\n",
       "      <td>0.416257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.069566</td>\n",
       "      <td>0.051616</td>\n",
       "      <td>0.173052</td>\n",
       "      <td>0.011397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.694865</td>\n",
       "      <td>0.725498</td>\n",
       "      <td>0.706075</td>\n",
       "      <td>0.795245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.872140</td>\n",
       "      <td>0.894935</td>\n",
       "      <td>0.887883</td>\n",
       "      <td>0.844346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.594260</td>\n",
       "      <td>0.622248</td>\n",
       "      <td>0.597176</td>\n",
       "      <td>0.759430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize  features  sample_vec\n",
       "fit_time        0.378491   0.325110  0.735161    0.416257\n",
       "score_time      0.069566   0.051616  0.173052    0.011397\n",
       "test_f1         0.694865   0.725498  0.706075    0.795245\n",
       "test_precision  0.872140   0.894935  0.887883    0.844346\n",
       "test_recall     0.594260   0.622248  0.597176    0.759430"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(min_df=10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer = feature_extraction.text.TfidfVectorizer(min_df=10)\n",
    "word_vectorizer.fit(vk_all['normalize_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', ngram_range=(2, 5), sublinear_tf=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vectorizer = feature_extraction.text.TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    analyzer='char',\n",
    "    ngram_range=(2,5))\n",
    "char_vectorizer.fit(vk_all['normalize_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_fu = pipeline.FeatureUnion([('idf_w',word_vectorizer),('idf_c',char_vectorizer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression()\n",
    "pipe_idf_fe = pipeline.Pipeline([('fu',idf_fu),('clf',clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['idf_features'] = pd.DataFrame(model_selection.cross_validate(pipe_idf_fe,vk_all['normalize_text'],vk_all['toxic'],scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "      <th>features</th>\n",
       "      <th>sample_vec</th>\n",
       "      <th>idf_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.378491</td>\n",
       "      <td>0.325110</td>\n",
       "      <td>0.735161</td>\n",
       "      <td>0.416257</td>\n",
       "      <td>9.148327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.069566</td>\n",
       "      <td>0.051616</td>\n",
       "      <td>0.173052</td>\n",
       "      <td>0.011397</td>\n",
       "      <td>1.040702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.694865</td>\n",
       "      <td>0.725498</td>\n",
       "      <td>0.706075</td>\n",
       "      <td>0.795245</td>\n",
       "      <td>0.797823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.872140</td>\n",
       "      <td>0.894935</td>\n",
       "      <td>0.887883</td>\n",
       "      <td>0.844346</td>\n",
       "      <td>0.905753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.594260</td>\n",
       "      <td>0.622248</td>\n",
       "      <td>0.597176</td>\n",
       "      <td>0.759430</td>\n",
       "      <td>0.725239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize  features  sample_vec  idf_features\n",
       "fit_time        0.378491   0.325110  0.735161    0.416257      9.148327\n",
       "score_time      0.069566   0.051616  0.173052    0.011397      1.040702\n",
       "test_f1         0.694865   0.725498  0.706075    0.795245      0.797823\n",
       "test_precision  0.872140   0.894935  0.887883    0.844346      0.905753\n",
       "test_recall     0.594260   0.622248  0.597176    0.759430      0.725239"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7801a1fce19b4dbca8b7bce4059e552648312323ed9d108616a9100a6d7a4a9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
