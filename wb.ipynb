{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/charubaiel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import lightgbm as lgbm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "nltk.download(\"stopwords\")\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pos \\ neg - комменты с твиттера http://study.mokoron.com/ \n",
    "# labeled каггловский датасет по токсикам https://www.kaggle.com/blackmoon/russian-language-toxic-comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_neg = pd.read_csv('data/negative.csv',sep=';',header=None,usecols=[3])\n",
    "twitter_pos = pd.read_csv('data/positive.csv',sep=';',header=None,usecols=[3])\n",
    "vk_all = pd.read_csv('data/labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl_toxic = vk_all.append(twitter_neg.rename(columns={3:'comment'})).fillna(1)\n",
    "df = ttl_toxic.append(twitter_pos.rename(columns={3:'comment'})).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.516058\n",
       "1.0    0.483942\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,val_data,target,val_target = model_selection.train_test_split(vk_all['comment'],vk_all['toxic'],train_size=.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stupid baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = feature_extraction.text.TfidfVectorizer(min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(min_df=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_base = linear_model.LogisticRegression(max_iter=1000)\n",
    "pipe_base = pipeline.make_pipeline(tf,clf_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['baseline'] = pd.DataFrame(model_selection.cross_validate(pipe_base,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(min_df=10)),\n",
       "                ('logisticregression', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_base.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.180401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.029296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.678159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.839016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.569149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline\n",
       "fit_time        0.180401\n",
       "score_time      0.029296\n",
       "test_f1         0.678159\n",
       "test_precision  0.839016\n",
       "test_recall     0.569149"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### work with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "stopwords = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer (text):\n",
    "    words_only = re.sub('[^А-я]+',' ',text.lower())\n",
    "    doc = Doc(words_only)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    clean_text = []\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "        if (token.lemma not in stopwords) & (len(set(token.lemma))>1):\n",
    "            clean_text.append(token.lemma)\n",
    "            \n",
    "    return ' '.join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_text = ' жожо '.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = normalizer(old_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = new_text.split('жожо')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val_data = val_data.copy()\n",
    "val_data = pd.Series(normalizer(' жожо '.join(val_data)).split('жожо'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_norm = linear_model.LogisticRegression(max_iter=1000)\n",
    "pipe_norm = pipeline.make_pipeline(tf,clf_norm)\n",
    "scores['normalize'] = pd.DataFrame(model_selection.cross_validate(pipe_norm,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(min_df=10)),\n",
       "                ('logisticregression', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_norm.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.180401</td>\n",
       "      <td>0.224762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.029296</td>\n",
       "      <td>0.027860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.678159</td>\n",
       "      <td>0.715096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.839016</td>\n",
       "      <td>0.892805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.569149</td>\n",
       "      <td>0.596822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize\n",
       "fit_time        0.180401   0.224762\n",
       "score_time      0.029296   0.027860\n",
       "test_f1         0.678159   0.715096\n",
       "test_precision  0.839016   0.892805\n",
       "test_recall     0.569149   0.596822"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### micro EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda = vk_all.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda['txt_len'] = eda['comment'].str.len()\n",
    "eda['txt_len_avg'] = eda['comment'].str.split().apply(lambda x: np.mean([len(word) for word in x]))\n",
    "eda['txt_words'] = eda['comment'].str.count(' ')\n",
    "eda['txt_puncts'] = eda['comment'].str.count('[^\\w^ ]')\n",
    "eda['txt_upper_cnt'] = eda['comment'].apply(lambda x: len([i for i in x if i.isupper()]))\n",
    "eda['txt_pct_upper'] = eda['txt_upper_cnt'] / eda['txt_len']\n",
    "eda['txt_pos_punc'] = eda['comment'].apply(lambda text: len(re.findall(r'\\)|D',text)))\n",
    "eda['txt_neg_punc'] = eda['comment'].apply(lambda text: len(re.findall(r'\\(|C|c|С|c',text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_len</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_len_avg</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_words</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_puncts</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_upper_cnt</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_pct_upper</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_pos_punc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_neg_punc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>194.213332</td>\n",
       "      <td>274.750067</td>\n",
       "      <td>5.312308</td>\n",
       "      <td>1.063207</td>\n",
       "      <td>29.713436</td>\n",
       "      <td>40.811415</td>\n",
       "      <td>7.481849</td>\n",
       "      <td>9.135183</td>\n",
       "      <td>3.984978</td>\n",
       "      <td>7.812980</td>\n",
       "      <td>0.023631</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>0.279261</td>\n",
       "      <td>0.709825</td>\n",
       "      <td>0.499478</td>\n",
       "      <td>1.353467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>141.392665</td>\n",
       "      <td>261.776417</td>\n",
       "      <td>5.467866</td>\n",
       "      <td>1.466984</td>\n",
       "      <td>21.449233</td>\n",
       "      <td>42.106635</td>\n",
       "      <td>5.972234</td>\n",
       "      <td>9.188326</td>\n",
       "      <td>6.595939</td>\n",
       "      <td>26.932055</td>\n",
       "      <td>0.052774</td>\n",
       "      <td>0.130923</td>\n",
       "      <td>0.094488</td>\n",
       "      <td>0.434023</td>\n",
       "      <td>0.454414</td>\n",
       "      <td>1.689128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          txt_len             txt_len_avg            txt_words             \\\n",
       "             mean         std        mean       std       mean        std   \n",
       "toxic                                                                       \n",
       "0.0    194.213332  274.750067    5.312308  1.063207  29.713436  40.811415   \n",
       "1.0    141.392665  261.776417    5.467866  1.466984  21.449233  42.106635   \n",
       "\n",
       "      txt_puncts           txt_upper_cnt            txt_pct_upper            \\\n",
       "            mean       std          mean        std          mean       std   \n",
       "toxic                                                                         \n",
       "0.0     7.481849  9.135183      3.984978   7.812980      0.023631  0.027502   \n",
       "1.0     5.972234  9.188326      6.595939  26.932055      0.052774  0.130923   \n",
       "\n",
       "      txt_pos_punc           txt_neg_punc            \n",
       "              mean       std         mean       std  \n",
       "toxic                                                \n",
       "0.0       0.279261  0.709825     0.499478  1.353467  \n",
       "1.0       0.094488  0.434023     0.454414  1.689128  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.groupby('toxic')[eda.filter(regex='txt').columns].agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>txt_len</th>\n",
       "      <th>txt_len_avg</th>\n",
       "      <th>txt_words</th>\n",
       "      <th>txt_puncts</th>\n",
       "      <th>txt_upper_cnt</th>\n",
       "      <th>txt_pct_upper</th>\n",
       "      <th>txt_pos_punc</th>\n",
       "      <th>txt_neg_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091782</td>\n",
       "      <td>0.060394</td>\n",
       "      <td>-0.094138</td>\n",
       "      <td>-0.077608</td>\n",
       "      <td>0.072997</td>\n",
       "      <td>0.171514</td>\n",
       "      <td>-0.136895</td>\n",
       "      <td>-0.014424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_len</th>\n",
       "      <td>-0.091782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024703</td>\n",
       "      <td>0.991756</td>\n",
       "      <td>0.924170</td>\n",
       "      <td>0.370052</td>\n",
       "      <td>-0.047513</td>\n",
       "      <td>0.382291</td>\n",
       "      <td>0.529863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_len_avg</th>\n",
       "      <td>0.060394</td>\n",
       "      <td>0.024703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025150</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.022158</td>\n",
       "      <td>0.079450</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>0.037176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_words</th>\n",
       "      <td>-0.094138</td>\n",
       "      <td>0.991756</td>\n",
       "      <td>-0.025150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929034</td>\n",
       "      <td>0.368631</td>\n",
       "      <td>-0.049015</td>\n",
       "      <td>0.378389</td>\n",
       "      <td>0.514993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_puncts</th>\n",
       "      <td>-0.077608</td>\n",
       "      <td>0.924170</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.929034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346096</td>\n",
       "      <td>-0.033393</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.497885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_upper_cnt</th>\n",
       "      <td>0.072997</td>\n",
       "      <td>0.370052</td>\n",
       "      <td>0.022158</td>\n",
       "      <td>0.368631</td>\n",
       "      <td>0.346096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565105</td>\n",
       "      <td>0.115176</td>\n",
       "      <td>0.692265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_pct_upper</th>\n",
       "      <td>0.171514</td>\n",
       "      <td>-0.047513</td>\n",
       "      <td>0.079450</td>\n",
       "      <td>-0.049015</td>\n",
       "      <td>-0.033393</td>\n",
       "      <td>0.565105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040094</td>\n",
       "      <td>0.312005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_pos_punc</th>\n",
       "      <td>-0.136895</td>\n",
       "      <td>0.382291</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>0.378389</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.115176</td>\n",
       "      <td>-0.040094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.395420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_neg_punc</th>\n",
       "      <td>-0.014424</td>\n",
       "      <td>0.529863</td>\n",
       "      <td>0.037176</td>\n",
       "      <td>0.514993</td>\n",
       "      <td>0.497885</td>\n",
       "      <td>0.692265</td>\n",
       "      <td>0.312005</td>\n",
       "      <td>0.395420</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  toxic   txt_len  txt_len_avg  txt_words  txt_puncts  \\\n",
       "toxic          1.000000 -0.091782     0.060394  -0.094138   -0.077608   \n",
       "txt_len       -0.091782  1.000000     0.024703   0.991756    0.924170   \n",
       "txt_len_avg    0.060394  0.024703     1.000000  -0.025150    0.016616   \n",
       "txt_words     -0.094138  0.991756    -0.025150   1.000000    0.929034   \n",
       "txt_puncts    -0.077608  0.924170     0.016616   0.929034    1.000000   \n",
       "txt_upper_cnt  0.072997  0.370052     0.022158   0.368631    0.346096   \n",
       "txt_pct_upper  0.171514 -0.047513     0.079450  -0.049015   -0.033393   \n",
       "txt_pos_punc  -0.136895  0.382291    -0.001665   0.378389    0.418016   \n",
       "txt_neg_punc  -0.014424  0.529863     0.037176   0.514993    0.497885   \n",
       "\n",
       "               txt_upper_cnt  txt_pct_upper  txt_pos_punc  txt_neg_punc  \n",
       "toxic               0.072997       0.171514     -0.136895     -0.014424  \n",
       "txt_len             0.370052      -0.047513      0.382291      0.529863  \n",
       "txt_len_avg         0.022158       0.079450     -0.001665      0.037176  \n",
       "txt_words           0.368631      -0.049015      0.378389      0.514993  \n",
       "txt_puncts          0.346096      -0.033393      0.418016      0.497885  \n",
       "txt_upper_cnt       1.000000       0.565105      0.115176      0.692265  \n",
       "txt_pct_upper       0.565105       1.000000     -0.040094      0.312005  \n",
       "txt_pos_punc        0.115176      -0.040094      1.000000      0.395420  \n",
       "txt_neg_punc        0.692265       0.312005      0.395420      1.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.iloc[:,1:].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_from_text(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns=['text']\n",
    "    df['txt_len'] = df['text'].str.len()\n",
    "    df['txt_len_avg'] = df['text'].str.split().apply(lambda x: np.mean([len(word) for word in x]))\n",
    "    df['txt_words'] = df['text'].str.count(' ')\n",
    "    df['txt_puncts'] = df['text'].str.count('[^\\w^ ]')\n",
    "    df['txt_upper_cnt'] = df['text'].apply(lambda x: len([i for i in x if i.isupper()]))\n",
    "    df['txt_pos_punc'] = df['text'].apply(lambda text: len(re.findall(r'\\)|D',text)))\n",
    "    df['txt_neg_punc'] = df['text'].apply(lambda text: len(re.findall(r'\\(|C|c|С|c',text)))\n",
    "    \n",
    "    return df.drop('text',axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_tf = feature_extraction.text.TfidfVectorizer(min_df=10)\n",
    "fe_tf.fit(data,target)\n",
    "new_fe=preprocessing.FunctionTransformer(features_from_text)\n",
    "text_preproc = pipeline.FeatureUnion([('idf',fe_tf),('fe',new_fe)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_fe = linear_model.LogisticRegression(max_iter=1000)\n",
    "pipe_fe = pipeline.Pipeline([('preproc',text_preproc),('clf',clf_fe)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "scores['features'] = pd.DataFrame(model_selection.cross_validate(pipe_fe,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preproc',\n",
       "                 FeatureUnion(transformer_list=[('idf',\n",
       "                                                 TfidfVectorizer(min_df=10)),\n",
       "                                                ('fe',\n",
       "                                                 FunctionTransformer(func=<function features_from_text at 0x7ff39901fee0>))])),\n",
       "                ('clf', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_fe.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.180401</td>\n",
       "      <td>0.224762</td>\n",
       "      <td>0.587189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.029296</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>0.066969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.678159</td>\n",
       "      <td>0.715096</td>\n",
       "      <td>0.717004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.839016</td>\n",
       "      <td>0.892805</td>\n",
       "      <td>0.888669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.569149</td>\n",
       "      <td>0.596822</td>\n",
       "      <td>0.601478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize  features\n",
       "fit_time        0.180401   0.224762  0.587189\n",
       "score_time      0.029296   0.027860  0.066969\n",
       "test_f1         0.678159   0.715096  0.717004\n",
       "test_precision  0.839016   0.892805  0.888669\n",
       "test_recall     0.569149   0.596822  0.601478"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav = Navec.load('emb_navec.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vecror(sentence_list):\n",
    "    vectors = []\n",
    "    for sentence in sentence_list:\n",
    "        sent_vec = []\n",
    "        for i in sentence.split():\n",
    "            if i in nav:\n",
    "                sent_vec.append(nav[i])\n",
    "            else:\n",
    "                sent_vec.append(nav['<unk>'])\n",
    "        if sentence.strip() == '':\n",
    "            sent_vec = [nav['<unk>']]\n",
    "        vectors.append(np.mean(sent_vec,axis=0))\n",
    "    return np.vstack(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_func = preprocessing.FunctionTransformer(get_sentence_vecror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_vec = linear_model.LogisticRegression(max_iter=1000)\n",
    "pipe_vec = pipeline.make_pipeline(vec_func,clf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['sample_vec'] = pd.DataFrame(model_selection.cross_validate(pipe_vec,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function get_sentence_vecror at 0x7ff38b283280>)),\n",
       "                ('logisticregression', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_vec.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "      <th>features</th>\n",
       "      <th>sample_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.180401</td>\n",
       "      <td>0.224762</td>\n",
       "      <td>0.587189</td>\n",
       "      <td>1.051636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.029296</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>0.066969</td>\n",
       "      <td>0.233051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.678159</td>\n",
       "      <td>0.715096</td>\n",
       "      <td>0.717004</td>\n",
       "      <td>0.807755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.839016</td>\n",
       "      <td>0.892805</td>\n",
       "      <td>0.888669</td>\n",
       "      <td>0.843106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.569149</td>\n",
       "      <td>0.596822</td>\n",
       "      <td>0.601478</td>\n",
       "      <td>0.775403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize  features  sample_vec\n",
       "fit_time        0.180401   0.224762  0.587189    1.051636\n",
       "score_time      0.029296   0.027860  0.066969    0.233051\n",
       "test_f1         0.678159   0.715096  0.717004    0.807755\n",
       "test_precision  0.839016   0.892805  0.888669    0.843106\n",
       "test_recall     0.569149   0.596822  0.601478    0.775403"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(min_df=10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer = feature_extraction.text.TfidfVectorizer(min_df=10)\n",
    "word_vectorizer.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', ngram_range=(2, 5), sublinear_tf=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vectorizer = feature_extraction.text.TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    analyzer='char',\n",
    "    ngram_range=(2,5))\n",
    "char_vectorizer.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_fu = pipeline.FeatureUnion([('idf_w',word_vectorizer),('idf_c',char_vectorizer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2idf = linear_model.LogisticRegression(max_iter=1000)\n",
    "pipe_idf_fe = pipeline.Pipeline([('idf',idf_fu),('clf',clf_2idf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['idf_features'] = pd.DataFrame(model_selection.cross_validate(pipe_idf_fe,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('idf',\n",
       "                 FeatureUnion(transformer_list=[('idf_w',\n",
       "                                                 TfidfVectorizer(min_df=10)),\n",
       "                                                ('idf_c',\n",
       "                                                 TfidfVectorizer(analyzer='char',\n",
       "                                                                 ngram_range=(2,\n",
       "                                                                              5),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                ('clf', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_idf_fe.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "      <th>features</th>\n",
       "      <th>sample_vec</th>\n",
       "      <th>idf_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.180401</td>\n",
       "      <td>0.224762</td>\n",
       "      <td>0.587189</td>\n",
       "      <td>1.051636</td>\n",
       "      <td>6.028868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.029296</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>0.066969</td>\n",
       "      <td>0.233051</td>\n",
       "      <td>0.507511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.678159</td>\n",
       "      <td>0.715096</td>\n",
       "      <td>0.717004</td>\n",
       "      <td>0.807755</td>\n",
       "      <td>0.794277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.839016</td>\n",
       "      <td>0.892805</td>\n",
       "      <td>0.888669</td>\n",
       "      <td>0.843106</td>\n",
       "      <td>0.901471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.569149</td>\n",
       "      <td>0.596822</td>\n",
       "      <td>0.601478</td>\n",
       "      <td>0.775403</td>\n",
       "      <td>0.710209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize  features  sample_vec  idf_features\n",
       "fit_time        0.180401   0.224762  0.587189    1.051636      6.028868\n",
       "score_time      0.029296   0.027860  0.066969    0.233051      0.507511\n",
       "test_f1         0.678159   0.715096  0.717004    0.807755      0.794277\n",
       "test_precision  0.839016   0.892805  0.888669    0.843106      0.901471\n",
       "test_recall     0.569149   0.596822  0.601478    0.775403      0.710209"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blend models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_func = preprocessing.FunctionTransformer(get_sentence_vecror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_vec = linear_model.LogisticRegression(max_iter=1000,C=6,penalty='l1',solver='liblinear')\n",
    "clf_nb_vec = naive_bayes.BernoulliNB()\n",
    "clf_knn_vec = neighbors.KNeighborsClassifier(30)\n",
    "clf_svc_vec = svm.SVC(probability=True)\n",
    "clf_rf_vec = lgbm.LGBMClassifier(n_estimators=1500,learning_rate=0.07,num_leaves=15)\n",
    "clf_mlp_vec = neural_network.MLPClassifier(hidden_layer_sizes=(300,1),max_iter=1000,learning_rate='adaptive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:09,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time          1.636022\n",
      "score_time        0.198677\n",
      "test_f1           0.807069\n",
      "test_precision    0.838823\n",
      "test_recall       0.777865\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:14,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time          0.806764\n",
      "score_time        0.230192\n",
      "test_f1           0.706233\n",
      "test_precision    0.707869\n",
      "test_recall       0.704732\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:20,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time          0.758724\n",
      "score_time        0.542445\n",
      "test_f1           0.769747\n",
      "test_precision    0.773026\n",
      "test_recall       0.766910\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:50, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time          4.472831\n",
      "score_time        1.376537\n",
      "test_f1           0.819420\n",
      "test_precision    0.849801\n",
      "test_recall       0.791290\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:25, 22.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time          6.770268\n",
      "score_time        0.217524\n",
      "test_f1           0.804337\n",
      "test_precision    0.842790\n",
      "test_recall       0.769376\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [02:23, 23.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time          11.366353\n",
      "score_time         0.222684\n",
      "test_f1            0.806354\n",
      "test_precision     0.812877\n",
      "test_recall        0.800879\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for n,model in tqdm(enumerate([clf_lr_vec,clf_nb_vec,clf_knn_vec,clf_svc_vec,clf_rf_vec,clf_mlp_vec])):\n",
    "    tmp_pipe = pipeline.make_pipeline(vec_func,model)\n",
    "    models[n] = pd.DataFrame(model_selection.cross_validate(tmp_pipe,data,target,scoring=['f1','precision','recall'],cv=5)).mean()\n",
    "    print(models[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>4.472831</td>\n",
       "      <td>1.376537</td>\n",
       "      <td>0.819420</td>\n",
       "      <td>0.849801</td>\n",
       "      <td>0.791290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>1.636022</td>\n",
       "      <td>0.198677</td>\n",
       "      <td>0.807069</td>\n",
       "      <td>0.838823</td>\n",
       "      <td>0.777865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>11.366353</td>\n",
       "      <td>0.222684</td>\n",
       "      <td>0.806354</td>\n",
       "      <td>0.812877</td>\n",
       "      <td>0.800879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbm</th>\n",
       "      <td>6.770268</td>\n",
       "      <td>0.217524</td>\n",
       "      <td>0.804337</td>\n",
       "      <td>0.842790</td>\n",
       "      <td>0.769376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.758724</td>\n",
       "      <td>0.542445</td>\n",
       "      <td>0.769747</td>\n",
       "      <td>0.773026</td>\n",
       "      <td>0.766910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>0.806764</td>\n",
       "      <td>0.230192</td>\n",
       "      <td>0.706233</td>\n",
       "      <td>0.707869</td>\n",
       "      <td>0.704732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time   test_f1  test_precision  test_recall\n",
       "svc   4.472831    1.376537  0.819420        0.849801     0.791290\n",
       "lr    1.636022    0.198677  0.807069        0.838823     0.777865\n",
       "mlp  11.366353    0.222684  0.806354        0.812877     0.800879\n",
       "gbm   6.770268    0.217524  0.804337        0.842790     0.769376\n",
       "knn   0.758724    0.542445  0.769747        0.773026     0.766910\n",
       "nb    0.806764    0.230192  0.706233        0.707869     0.704732"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(models).rename(columns = {0:'lr',1:'nb',2:'knn',3:'svc',4:'gbm',5:'mlp'}).T.sort_values(by='test_f1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vote_vec = ensemble.VotingClassifier(estimators=[('lr',clf_lr_vec),('nb',clf_nb_vec),('knn',clf_knn_vec),('svc',clf_svc_vec),('gbm',clf_rf_vec),('mlp',clf_mlp_vec)],voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_vote_vec = pipeline.make_pipeline(vec_func,vote_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['vote_models'] = pd.DataFrame(model_selection.cross_validate(pipe_vote_vec,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function get_sentence_vecror at 0x7ff38b283280>)),\n",
       "                ('votingclassifier',\n",
       "                 VotingClassifier(estimators=[('lr',\n",
       "                                               LogisticRegression(C=6,\n",
       "                                                                  max_iter=1000,\n",
       "                                                                  penalty='l1',\n",
       "                                                                  solver='liblinear')),\n",
       "                                              ('nb', BernoulliNB()),\n",
       "                                              ('knn',\n",
       "                                               KNeighborsClassifier(n_neighbors=30)),\n",
       "                                              ('svc', SVC(probability=True)),\n",
       "                                              ('gbm',\n",
       "                                               LGBMClassifier(learning_rate=0.07,\n",
       "                                                              n_estimators=1500,\n",
       "                                                              num_leaves=15)),\n",
       "                                              ('mlp',\n",
       "                                               MLPClassifier(hidden_layer_sizes=(300,\n",
       "                                                                                 1),\n",
       "                                                             learning_rate='adaptive',\n",
       "                                                             max_iter=1000))],\n",
       "                                  voting='soft'))])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_vote_vec.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "      <th>features</th>\n",
       "      <th>sample_vec</th>\n",
       "      <th>idf_features</th>\n",
       "      <th>vote_models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.180401</td>\n",
       "      <td>0.224762</td>\n",
       "      <td>0.587189</td>\n",
       "      <td>1.051636</td>\n",
       "      <td>6.028868</td>\n",
       "      <td>48.953206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.029296</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>0.066969</td>\n",
       "      <td>0.233051</td>\n",
       "      <td>0.507511</td>\n",
       "      <td>1.718827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.678159</td>\n",
       "      <td>0.715096</td>\n",
       "      <td>0.717004</td>\n",
       "      <td>0.807755</td>\n",
       "      <td>0.794277</td>\n",
       "      <td>0.814480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.839016</td>\n",
       "      <td>0.892805</td>\n",
       "      <td>0.888669</td>\n",
       "      <td>0.843106</td>\n",
       "      <td>0.901471</td>\n",
       "      <td>0.836196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.569149</td>\n",
       "      <td>0.596822</td>\n",
       "      <td>0.601478</td>\n",
       "      <td>0.775403</td>\n",
       "      <td>0.710209</td>\n",
       "      <td>0.794025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize  features  sample_vec  idf_features  \\\n",
       "fit_time        0.180401   0.224762  0.587189    1.051636      6.028868   \n",
       "score_time      0.029296   0.027860  0.066969    0.233051      0.507511   \n",
       "test_f1         0.678159   0.715096  0.717004    0.807755      0.794277   \n",
       "test_precision  0.839016   0.892805  0.888669    0.843106      0.901471   \n",
       "test_recall     0.569149   0.596822  0.601478    0.775403      0.710209   \n",
       "\n",
       "                vote_models  \n",
       "fit_time          48.953206  \n",
       "score_time         1.718827  \n",
       "test_f1            0.814480  \n",
       "test_precision     0.836196  \n",
       "test_recall        0.794025  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blend results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(estimators,x,func=np.mean):\n",
    "    probs = []\n",
    "    for i in estimators:\n",
    "        probs.append(i.predict_proba(x)[:,1])\n",
    "    return np.apply_over_axes(func,np.array(probs),axes=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "eval_data = defaultdict(list)\n",
    "for model in [pipe_norm,pipe_fe,pipe_idf_fe,pipe_vec,pipe_vote_vec]:\n",
    "    eval_data['f1'].append(metrics.f1_score(val_target,model.predict(val_data)))\n",
    "    eval_data['recall'].append(metrics.recall_score(val_target,model.predict(val_data)))\n",
    "    eval_data['precision'].append(metrics.precision_score(val_target,model.predict(val_data)))\n",
    "    eval_data['roc_auc'].append(metrics.roc_auc_score(val_target,model.predict(val_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data['f1'].append(metrics.f1_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data).round()))\n",
    "eval_data['recall'].append(metrics.recall_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data).round()))\n",
    "eval_data['precision'].append(metrics.precision_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data).round()))\n",
    "eval_data['roc_auc'].append(metrics.roc_auc_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data).round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data['f1'].append(metrics.f1_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data,func=np.max).round()))\n",
    "eval_data['recall'].append(metrics.recall_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data,func=np.max).round()))\n",
    "eval_data['precision'].append(metrics.precision_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data,func=np.max).round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data['roc_auc'].append(metrics.roc_auc_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data,func=np.max).round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blend_max</th>\n",
       "      <td>0.841494</td>\n",
       "      <td>0.862979</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.885979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blend_mean</th>\n",
       "      <td>0.814215</td>\n",
       "      <td>0.770213</td>\n",
       "      <td>0.863550</td>\n",
       "      <td>0.855658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idf_df</th>\n",
       "      <td>0.808789</td>\n",
       "      <td>0.736170</td>\n",
       "      <td>0.897303</td>\n",
       "      <td>0.847698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote_vec</th>\n",
       "      <td>0.806563</td>\n",
       "      <td>0.794894</td>\n",
       "      <td>0.818580</td>\n",
       "      <td>0.854819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vec</th>\n",
       "      <td>0.801754</td>\n",
       "      <td>0.777872</td>\n",
       "      <td>0.827149</td>\n",
       "      <td>0.849603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fe</th>\n",
       "      <td>0.734491</td>\n",
       "      <td>0.629787</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.794301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm</th>\n",
       "      <td>0.733433</td>\n",
       "      <td>0.626383</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.793422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  f1    recall  precision   roc_auc\n",
       "blend_max   0.841494  0.862979   0.821053  0.885979\n",
       "blend_mean  0.814215  0.770213   0.863550  0.855658\n",
       "idf_df      0.808789  0.736170   0.897303  0.847698\n",
       "vote_vec    0.806563  0.794894   0.818580  0.854819\n",
       "vec         0.801754  0.777872   0.827149  0.849603\n",
       "fe          0.734491  0.629787   0.880952  0.794301\n",
       "norm        0.733433  0.626383   0.884615  0.793422"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(eval_data,index=['norm','fe','idf_df','vec','vote_vec','blend_mean','blend_max']).sort_values(by='f1',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_text (text):\n",
    "    return pd.Series({'pure_idf_model' : pipe_norm.predict_proba([text])[:,1][0],\n",
    "    'some_features_model' : pipe_fe.predict_proba([text])[:,1][0],\n",
    "    'double_idf_model' :pipe_idf_fe.predict_proba([text])[:,1][0],\n",
    "    'pure_vectors_model' :pipe_vec.predict_proba([text])[:,1][0],\n",
    "    'blending_models' : pipe_vote_vec.predict_proba([text])[:,1][0],\n",
    "    'blending_ttl_mean' : voting([pipe_vec,pipe_idf_fe],[text],func=np.mean)[0],\n",
    "    'blending_ttl_max' : voting([pipe_vec,pipe_idf_fe],[text],func=np.max)[0]},name='Степень токсичности')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_text (text):\n",
    "    return pd.Series({'pure_idf_model' : pipe_norm.predict_proba([text])[:,1][0],\n",
    "    'some_features_model' : pipe_fe.predict_proba([text])[:,1][0],\n",
    "    'double_idf_model' :pipe_idf_fe.predict_proba([text])[:,1][0],\n",
    "    'pure_vectors_model' :pipe_vec.predict_proba([text])[:,1][0],\n",
    "    # 'blending_models' : pipe_vote_vec.predict_proba([text])[:,1][0],\n",
    "    'blending_ttl_mean' : voting([pipe_vec,pipe_idf_fe],[text],func=np.mean)[0],\n",
    "    'blending_ttl_max' : voting([pipe_vec,pipe_idf_fe],[text],func=np.max)[0]},name='Степень токсичности')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_predict(model,text):\n",
    "    return model.predict_proba([text])[:,1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 µs ± 3.29 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "time_predict(pipe_norm,'Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.68 ms ± 82.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "time_predict(pipe_fe,'Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18 ms ± 253 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "time_predict(pipe_idf_fe,'Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 µs ± 6.55 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "time_predict(pipe_vec,'Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.6 ms ± 5.41 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "time_predict(pipe_vote_vec,'Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ms ± 28.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "check_text('Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pure_idf_model         0.425171\n",
       "some_features_model    0.494172\n",
       "double_idf_model       0.457508\n",
       "pure_vectors_model     0.207928\n",
       "blending_ttl_mean      0.332718\n",
       "blending_ttl_max       0.457508\n",
       "Name: Степень токсичности, dtype: float64"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_text('Уроды у нас в семье 3 поколения там родились')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a66d7_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Степень токсичности</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a66d7_level0_row0\" class=\"row_heading level0 row0\" >pure_idf_model</th>\n",
       "      <td id=\"T_a66d7_row0_col0\" class=\"data row0 col0\" >68.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a66d7_level0_row1\" class=\"row_heading level0 row1\" >some_features_model</th>\n",
       "      <td id=\"T_a66d7_row1_col0\" class=\"data row1 col0\" >76.55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a66d7_level0_row2\" class=\"row_heading level0 row2\" >double_idf_model</th>\n",
       "      <td id=\"T_a66d7_row2_col0\" class=\"data row2 col0\" >69.47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a66d7_level0_row3\" class=\"row_heading level0 row3\" >pure_vectors_model</th>\n",
       "      <td id=\"T_a66d7_row3_col0\" class=\"data row3 col0\" >53.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a66d7_level0_row4\" class=\"row_heading level0 row4\" >blending_ttl_mean</th>\n",
       "      <td id=\"T_a66d7_row4_col0\" class=\"data row4 col0\" >61.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a66d7_level0_row5\" class=\"row_heading level0 row5\" >blending_ttl_max</th>\n",
       "      <td id=\"T_a66d7_row5_col0\" class=\"data row5 col0\" >69.47%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff38b1b9a90>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_text('Ну в целом я хочу сказать что товар не плохой, а просто каличный - я рот его ебал').to_frame().style.format('{:.2%}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7801a1fce19b4dbca8b7bce4059e552648312323ed9d108616a9100a6d7a4a9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
