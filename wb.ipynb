{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/charubaiel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "nltk.download(\"stopwords\")\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pos \\ neg - комменты с твиттера http://study.mokoron.com/ \n",
    "# labeled каггловский датасет по токсикам https://www.kaggle.com/blackmoon/russian-language-toxic-comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_neg = pd.read_csv('data/negative.csv',sep=';',header=None,usecols=[3])\n",
    "twitter_pos = pd.read_csv('data/positive.csv',sep=';',header=None,usecols=[3])\n",
    "vk_all = pd.read_csv('data/labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl_toxic = vk_all.append(twitter_neg.rename(columns={3:'comment'})).fillna(1)\n",
    "df = ttl_toxic.append(twitter_pos.rename(columns={3:'comment'})).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.516058\n",
       "1.0    0.483942\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,val_data,target,val_target = model_selection.train_test_split(vk_all['comment'],vk_all['toxic'],train_size=.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stupid baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = feature_extraction.text.TfidfVectorizer(min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(min_df=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_base = linear_model.LogisticRegression(max_iter=1000)\n",
    "pipe_base = pipeline.make_pipeline(tf,clf_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['baseline'] = pd.DataFrame(model_selection.cross_validate(pipe_base,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(min_df=10)),\n",
       "                ('logisticregression', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_base.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.242109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.039719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.670582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.836171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.559889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline\n",
       "fit_time        0.242109\n",
       "score_time      0.039719\n",
       "test_f1         0.670582\n",
       "test_precision  0.836171\n",
       "test_recall     0.559889"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### work with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "stopwords = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer (text):\n",
    "    words_only = re.sub('[^А-я]+',' ',text.lower())\n",
    "    doc = Doc(words_only)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    clean_text = []\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "        if (token.lemma not in stopwords) & (len(set(token.lemma))>1):\n",
    "            clean_text.append(token.lemma)\n",
    "            \n",
    "    return ' '.join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_text = ' жожо '.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = normalizer(old_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = new_text.split('жожо')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_norm = linear_model.LogisticRegression(max_iter=1000)\n",
    "pipe_norm = pipeline.make_pipeline(tf,clf_norm)\n",
    "scores['normalize'] = pd.DataFrame(model_selection.cross_validate(pipe_norm,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(min_df=10)),\n",
       "                ('logisticregression', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_norm.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.242109</td>\n",
       "      <td>0.168174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.039719</td>\n",
       "      <td>0.025518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.670582</td>\n",
       "      <td>0.704610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.836171</td>\n",
       "      <td>0.877150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.559889</td>\n",
       "      <td>0.588935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize\n",
       "fit_time        0.242109   0.168174\n",
       "score_time      0.039719   0.025518\n",
       "test_f1         0.670582   0.704610\n",
       "test_precision  0.836171   0.877150\n",
       "test_recall     0.559889   0.588935"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### micro EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda = vk_all.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda['txt_len'] = eda['comment'].str.len()\n",
    "eda['txt_len_avg'] = eda['comment'].str.split().apply(lambda x: np.mean([len(word) for word in x]))\n",
    "eda['txt_words'] = eda['comment'].str.count(' ')\n",
    "eda['txt_puncts'] = eda['comment'].str.count('[^\\w^ ]')\n",
    "eda['txt_upper_cnt'] = eda['comment'].apply(lambda x: len([i for i in x if i.isupper()]))\n",
    "eda['txt_pct_upper'] = eda['txt_upper_cnt'] / eda['txt_len']\n",
    "eda['txt_pos_punc'] = eda['comment'].apply(lambda text: len(re.findall(r'\\)|D',text)))\n",
    "eda['txt_neg_punc'] = eda['comment'].apply(lambda text: len(re.findall(r'\\(|C|c|С|c',text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_len</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_len_avg</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_words</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_puncts</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_upper_cnt</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_pct_upper</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_pos_punc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">txt_neg_punc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>194.213332</td>\n",
       "      <td>274.750067</td>\n",
       "      <td>5.312308</td>\n",
       "      <td>1.063207</td>\n",
       "      <td>29.713436</td>\n",
       "      <td>40.811415</td>\n",
       "      <td>7.481849</td>\n",
       "      <td>9.135183</td>\n",
       "      <td>3.984978</td>\n",
       "      <td>7.812980</td>\n",
       "      <td>0.023631</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>0.279261</td>\n",
       "      <td>0.709825</td>\n",
       "      <td>0.499478</td>\n",
       "      <td>1.353467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>141.392665</td>\n",
       "      <td>261.776417</td>\n",
       "      <td>5.467866</td>\n",
       "      <td>1.466984</td>\n",
       "      <td>21.449233</td>\n",
       "      <td>42.106635</td>\n",
       "      <td>5.972234</td>\n",
       "      <td>9.188326</td>\n",
       "      <td>6.595939</td>\n",
       "      <td>26.932055</td>\n",
       "      <td>0.052774</td>\n",
       "      <td>0.130923</td>\n",
       "      <td>0.094488</td>\n",
       "      <td>0.434023</td>\n",
       "      <td>0.454414</td>\n",
       "      <td>1.689128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          txt_len             txt_len_avg            txt_words             \\\n",
       "             mean         std        mean       std       mean        std   \n",
       "toxic                                                                       \n",
       "0.0    194.213332  274.750067    5.312308  1.063207  29.713436  40.811415   \n",
       "1.0    141.392665  261.776417    5.467866  1.466984  21.449233  42.106635   \n",
       "\n",
       "      txt_puncts           txt_upper_cnt            txt_pct_upper            \\\n",
       "            mean       std          mean        std          mean       std   \n",
       "toxic                                                                         \n",
       "0.0     7.481849  9.135183      3.984978   7.812980      0.023631  0.027502   \n",
       "1.0     5.972234  9.188326      6.595939  26.932055      0.052774  0.130923   \n",
       "\n",
       "      txt_pos_punc           txt_neg_punc            \n",
       "              mean       std         mean       std  \n",
       "toxic                                                \n",
       "0.0       0.279261  0.709825     0.499478  1.353467  \n",
       "1.0       0.094488  0.434023     0.454414  1.689128  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.groupby('toxic')[eda.filter(regex='txt').columns].agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>txt_len</th>\n",
       "      <th>txt_len_avg</th>\n",
       "      <th>txt_words</th>\n",
       "      <th>txt_puncts</th>\n",
       "      <th>txt_upper_cnt</th>\n",
       "      <th>txt_pct_upper</th>\n",
       "      <th>txt_pos_punc</th>\n",
       "      <th>txt_neg_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091782</td>\n",
       "      <td>0.060394</td>\n",
       "      <td>-0.094138</td>\n",
       "      <td>-0.077608</td>\n",
       "      <td>0.072997</td>\n",
       "      <td>0.171514</td>\n",
       "      <td>-0.136895</td>\n",
       "      <td>-0.014424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_len</th>\n",
       "      <td>-0.091782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024703</td>\n",
       "      <td>0.991756</td>\n",
       "      <td>0.924170</td>\n",
       "      <td>0.370052</td>\n",
       "      <td>-0.047513</td>\n",
       "      <td>0.382291</td>\n",
       "      <td>0.529863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_len_avg</th>\n",
       "      <td>0.060394</td>\n",
       "      <td>0.024703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025150</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.022158</td>\n",
       "      <td>0.079450</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>0.037176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_words</th>\n",
       "      <td>-0.094138</td>\n",
       "      <td>0.991756</td>\n",
       "      <td>-0.025150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929034</td>\n",
       "      <td>0.368631</td>\n",
       "      <td>-0.049015</td>\n",
       "      <td>0.378389</td>\n",
       "      <td>0.514993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_puncts</th>\n",
       "      <td>-0.077608</td>\n",
       "      <td>0.924170</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.929034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346096</td>\n",
       "      <td>-0.033393</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.497885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_upper_cnt</th>\n",
       "      <td>0.072997</td>\n",
       "      <td>0.370052</td>\n",
       "      <td>0.022158</td>\n",
       "      <td>0.368631</td>\n",
       "      <td>0.346096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565105</td>\n",
       "      <td>0.115176</td>\n",
       "      <td>0.692265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_pct_upper</th>\n",
       "      <td>0.171514</td>\n",
       "      <td>-0.047513</td>\n",
       "      <td>0.079450</td>\n",
       "      <td>-0.049015</td>\n",
       "      <td>-0.033393</td>\n",
       "      <td>0.565105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040094</td>\n",
       "      <td>0.312005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_pos_punc</th>\n",
       "      <td>-0.136895</td>\n",
       "      <td>0.382291</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>0.378389</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.115176</td>\n",
       "      <td>-0.040094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.395420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_neg_punc</th>\n",
       "      <td>-0.014424</td>\n",
       "      <td>0.529863</td>\n",
       "      <td>0.037176</td>\n",
       "      <td>0.514993</td>\n",
       "      <td>0.497885</td>\n",
       "      <td>0.692265</td>\n",
       "      <td>0.312005</td>\n",
       "      <td>0.395420</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  toxic   txt_len  txt_len_avg  txt_words  txt_puncts  \\\n",
       "toxic          1.000000 -0.091782     0.060394  -0.094138   -0.077608   \n",
       "txt_len       -0.091782  1.000000     0.024703   0.991756    0.924170   \n",
       "txt_len_avg    0.060394  0.024703     1.000000  -0.025150    0.016616   \n",
       "txt_words     -0.094138  0.991756    -0.025150   1.000000    0.929034   \n",
       "txt_puncts    -0.077608  0.924170     0.016616   0.929034    1.000000   \n",
       "txt_upper_cnt  0.072997  0.370052     0.022158   0.368631    0.346096   \n",
       "txt_pct_upper  0.171514 -0.047513     0.079450  -0.049015   -0.033393   \n",
       "txt_pos_punc  -0.136895  0.382291    -0.001665   0.378389    0.418016   \n",
       "txt_neg_punc  -0.014424  0.529863     0.037176   0.514993    0.497885   \n",
       "\n",
       "               txt_upper_cnt  txt_pct_upper  txt_pos_punc  txt_neg_punc  \n",
       "toxic               0.072997       0.171514     -0.136895     -0.014424  \n",
       "txt_len             0.370052      -0.047513      0.382291      0.529863  \n",
       "txt_len_avg         0.022158       0.079450     -0.001665      0.037176  \n",
       "txt_words           0.368631      -0.049015      0.378389      0.514993  \n",
       "txt_puncts          0.346096      -0.033393      0.418016      0.497885  \n",
       "txt_upper_cnt       1.000000       0.565105      0.115176      0.692265  \n",
       "txt_pct_upper       0.565105       1.000000     -0.040094      0.312005  \n",
       "txt_pos_punc        0.115176      -0.040094      1.000000      0.395420  \n",
       "txt_neg_punc        0.692265       0.312005      0.395420      1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.iloc[:,1:].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_from_text(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns=['text']\n",
    "    df['txt_len'] = df['text'].str.len()\n",
    "    df['txt_len_avg'] = df['text'].str.split().apply(lambda x: np.mean([len(word) for word in x]))\n",
    "    df['txt_words'] = df['text'].str.count(' ')\n",
    "    df['txt_puncts'] = df['text'].str.count('[^\\w^ ]')\n",
    "    df['txt_upper_cnt'] = df['text'].apply(lambda x: len([i for i in x if i.isupper()]))\n",
    "    df['txt_pos_punc'] = df['text'].apply(lambda text: len(re.findall(r'\\)|D',text)))\n",
    "    df['txt_neg_punc'] = df['text'].apply(lambda text: len(re.findall(r'\\(|C|c|С|c',text)))\n",
    "    \n",
    "    return df.drop('text',axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_tf = feature_extraction.text.TfidfVectorizer(min_df=10)\n",
    "fe_tf.fit(data,target)\n",
    "new_fe=preprocessing.FunctionTransformer(features_from_text)\n",
    "text_preproc = pipeline.FeatureUnion([('idf',fe_tf),('fe',new_fe)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_fe = linear_model.LogisticRegression(max_iter=1000)\n",
    "pipe_fe = pipeline.Pipeline([('preproc',text_preproc),('clf',clf_fe)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "scores['features'] = pd.DataFrame(model_selection.cross_validate(pipe_fe,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preproc',\n",
       "                 FeatureUnion(transformer_list=[('idf',\n",
       "                                                 TfidfVectorizer(min_df=10)),\n",
       "                                                ('fe',\n",
       "                                                 FunctionTransformer(func=<function features_from_text at 0x7f92b818fe50>))])),\n",
       "                ('clf', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_fe.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.242109</td>\n",
       "      <td>0.168174</td>\n",
       "      <td>0.618072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.039719</td>\n",
       "      <td>0.025518</td>\n",
       "      <td>0.076721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.670582</td>\n",
       "      <td>0.704610</td>\n",
       "      <td>0.708455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.836171</td>\n",
       "      <td>0.877150</td>\n",
       "      <td>0.875075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.559889</td>\n",
       "      <td>0.588935</td>\n",
       "      <td>0.595297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize  features\n",
       "fit_time        0.242109   0.168174  0.618072\n",
       "score_time      0.039719   0.025518  0.076721\n",
       "test_f1         0.670582   0.704610  0.708455\n",
       "test_precision  0.836171   0.877150  0.875075\n",
       "test_recall     0.559889   0.588935  0.595297"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav = Navec.load('emb_navec.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vecror(sentence_list):\n",
    "    vectors = []\n",
    "    for sentence in sentence_list:\n",
    "        sent_vec = []\n",
    "        for i in sentence.split():\n",
    "            if i in nav:\n",
    "                sent_vec.append(nav[i])\n",
    "            else:\n",
    "                sent_vec.append(nav['<unk>'])\n",
    "        if sentence.strip() == '':\n",
    "            sent_vec = [nav['<unk>']]\n",
    "        vectors.append(np.mean(sent_vec,axis=0))\n",
    "    return np.vstack(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_func = preprocessing.FunctionTransformer(get_sentence_vecror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_vec = linear_model.LogisticRegression(max_iter=1000)\n",
    "pipe_vec = pipeline.make_pipeline(vec_func,clf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['sample_vec'] = pd.DataFrame(model_selection.cross_validate(pipe_vec,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function get_sentence_vecror at 0x7f92b5df8af0>)),\n",
       "                ('logisticregression', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_vec.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "      <th>features</th>\n",
       "      <th>sample_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.242109</td>\n",
       "      <td>0.168174</td>\n",
       "      <td>0.618072</td>\n",
       "      <td>1.262928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.039719</td>\n",
       "      <td>0.025518</td>\n",
       "      <td>0.076721</td>\n",
       "      <td>0.278110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.670582</td>\n",
       "      <td>0.704610</td>\n",
       "      <td>0.708455</td>\n",
       "      <td>0.800196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.836171</td>\n",
       "      <td>0.877150</td>\n",
       "      <td>0.875075</td>\n",
       "      <td>0.832169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.559889</td>\n",
       "      <td>0.588935</td>\n",
       "      <td>0.595297</td>\n",
       "      <td>0.770678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize  features  sample_vec\n",
       "fit_time        0.242109   0.168174  0.618072    1.262928\n",
       "score_time      0.039719   0.025518  0.076721    0.278110\n",
       "test_f1         0.670582   0.704610  0.708455    0.800196\n",
       "test_precision  0.836171   0.877150  0.875075    0.832169\n",
       "test_recall     0.559889   0.588935  0.595297    0.770678"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(min_df=10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer = feature_extraction.text.TfidfVectorizer(min_df=10)\n",
    "word_vectorizer.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', ngram_range=(2, 5), sublinear_tf=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vectorizer = feature_extraction.text.TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    analyzer='char',\n",
    "    ngram_range=(2,5))\n",
    "char_vectorizer.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_fu = pipeline.FeatureUnion([('idf_w',word_vectorizer),('idf_c',char_vectorizer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2idf = linear_model.LogisticRegression(max_iter=1000)\n",
    "pipe_idf_fe = pipeline.Pipeline([('idf',idf_fu),('clf',clf_2idf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['idf_features'] = pd.DataFrame(model_selection.cross_validate(pipe_idf_fe,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('idf',\n",
       "                 FeatureUnion(transformer_list=[('idf_w',\n",
       "                                                 TfidfVectorizer(min_df=10)),\n",
       "                                                ('idf_c',\n",
       "                                                 TfidfVectorizer(analyzer='char',\n",
       "                                                                 ngram_range=(2,\n",
       "                                                                              5),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                ('clf', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_idf_fe.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "      <th>features</th>\n",
       "      <th>sample_vec</th>\n",
       "      <th>idf_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.242109</td>\n",
       "      <td>0.168174</td>\n",
       "      <td>0.618072</td>\n",
       "      <td>1.262928</td>\n",
       "      <td>6.238955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.039719</td>\n",
       "      <td>0.025518</td>\n",
       "      <td>0.076721</td>\n",
       "      <td>0.278110</td>\n",
       "      <td>0.583107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.670582</td>\n",
       "      <td>0.704610</td>\n",
       "      <td>0.708455</td>\n",
       "      <td>0.800196</td>\n",
       "      <td>0.792038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.836171</td>\n",
       "      <td>0.877150</td>\n",
       "      <td>0.875075</td>\n",
       "      <td>0.832169</td>\n",
       "      <td>0.897874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.559889</td>\n",
       "      <td>0.588935</td>\n",
       "      <td>0.595297</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.708714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize  features  sample_vec  idf_features\n",
       "fit_time        0.242109   0.168174  0.618072    1.262928      6.238955\n",
       "score_time      0.039719   0.025518  0.076721    0.278110      0.583107\n",
       "test_f1         0.670582   0.704610  0.708455    0.800196      0.792038\n",
       "test_precision  0.836171   0.877150  0.875075    0.832169      0.897874\n",
       "test_recall     0.559889   0.588935  0.595297    0.770678      0.708714"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blend models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_func = preprocessing.FunctionTransformer(get_sentence_vecror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_vec = linear_model.LogisticRegression(max_iter=1000,C=6,penalty='l1',solver='liblinear')\n",
    "clf_nb_vec = naive_bayes.BernoulliNB()\n",
    "clf_knn_vec = neighbors.KNeighborsClassifier(30)\n",
    "clf_svc_vec = svm.SVC()\n",
    "clf_mlp_vec = neural_network.MLPClassifier(max_iter=500)\n",
    "clf_rf_vec = ensemble.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [01:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/charubaiel/projects/nlp_otp_hw/wb.ipynb Cell 57'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/charubaiel/projects/nlp_otp_hw/wb.ipynb#ch0000215vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(np\u001b[39m.\u001b[39marange(\u001b[39m10\u001b[39m,\u001b[39m120\u001b[39m,\u001b[39m10\u001b[39m)):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/charubaiel/projects/nlp_otp_hw/wb.ipynb#ch0000215vscode-remote?line=2'>3</a>\u001b[0m     tmp_data \u001b[39m=\u001b[39m vec_func\u001b[39m.\u001b[39mtransform(data)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/charubaiel/projects/nlp_otp_hw/wb.ipynb#ch0000215vscode-remote?line=3'>4</a>\u001b[0m     clf \u001b[39m=\u001b[39m ensemble\u001b[39m.\u001b[39;49mRandomForestClassifier(max_depth \u001b[39m=\u001b[39;49mi,n_estimators\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(tmp_data,target)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/charubaiel/projects/nlp_otp_hw/wb.ipynb#ch0000215vscode-remote?line=4'>5</a>\u001b[0m     tmp_val_data \u001b[39m=\u001b[39m vec_func\u001b[39m.\u001b[39mtransform(val_data)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/charubaiel/projects/nlp_otp_hw/wb.ipynb#ch0000215vscode-remote?line=5'>6</a>\u001b[0m     plot_metrics[i]\u001b[39m=\u001b[39mmetrics\u001b[39m.\u001b[39mf1_score(val_target,clf\u001b[39m.\u001b[39mpredict(tmp_val_data))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=438'>439</a>\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=439'>440</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=440'>441</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=441'>442</a>\u001b[0m ]\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=443'>444</a>\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=444'>445</a>\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=445'>446</a>\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=446'>447</a>\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=447'>448</a>\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=448'>449</a>\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=449'>450</a>\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=450'>451</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=451'>452</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=452'>453</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=453'>454</a>\u001b[0m )(\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=454'>455</a>\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=455'>456</a>\u001b[0m         t,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=456'>457</a>\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=457'>458</a>\u001b[0m         X,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=458'>459</a>\u001b[0m         y,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=459'>460</a>\u001b[0m         sample_weight,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=460'>461</a>\u001b[0m         i,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=461'>462</a>\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=462'>463</a>\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=463'>464</a>\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=464'>465</a>\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=465'>466</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=466'>467</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=467'>468</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=469'>470</a>\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=470'>471</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=1042'>1043</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=1043'>1044</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=1045'>1046</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=1046'>1047</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=1049'>1050</a>\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=1050'>1051</a>\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=1051'>1052</a>\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=858'>859</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=859'>860</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=860'>861</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=861'>862</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=776'>777</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=777'>778</a>\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=778'>779</a>\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=779'>780</a>\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=780'>781</a>\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=781'>782</a>\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=782'>783</a>\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=783'>784</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=205'>206</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=206'>207</a>\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=207'>208</a>\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=208'>209</a>\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=209'>210</a>\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=569'>570</a>\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=570'>571</a>\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=571'>572</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py?line=213'>214</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py?line=214'>215</a>\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py?line=215'>216</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=181'>182</a>\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=182'>183</a>\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=184'>185</a>\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=185'>186</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=186'>187</a>\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=898'>899</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=899'>900</a>\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=900'>901</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=901'>902</a>\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=902'>903</a>\u001b[0m \n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=903'>904</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=933'>934</a>\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=934'>935</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=936'>937</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=937'>938</a>\u001b[0m         X,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=938'>939</a>\u001b[0m         y,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=939'>940</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=940'>941</a>\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=941'>942</a>\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=942'>943</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=943'>944</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=408'>409</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=409'>410</a>\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=410'>411</a>\u001b[0m         splitter,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=411'>412</a>\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=416'>417</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=417'>418</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=419'>420</a>\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=421'>422</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py?line=422'>423</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_metrics = {}\n",
    "for i in tqdm(np.arange(10,120,10)):\n",
    "    tmp_data = vec_func.transform(data)\n",
    "    clf = ensemble.RandomForestClassifier(max_depth =i,n_estimators=1000).fit(tmp_data,target)\n",
    "    tmp_val_data = vec_func.transform(val_data)\n",
    "    plot_metrics[i]=metrics.f1_score(val_target,clf.predict(tmp_val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(plot_metrics).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time          1.212226\n",
      "score_time        0.270333\n",
      "test_f1           0.800196\n",
      "test_precision    0.832169\n",
      "test_recall       0.770678\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:14,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time          1.067528\n",
      "score_time        0.284028\n",
      "test_f1           0.709332\n",
      "test_precision    0.709422\n",
      "test_recall       0.709544\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:22,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time          1.039625\n",
      "score_time        0.621425\n",
      "test_f1           0.738581\n",
      "test_precision    0.706601\n",
      "test_recall       0.774274\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:02, 20.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time          6.360856\n",
      "score_time        1.660540\n",
      "test_f1           0.813744\n",
      "test_precision    0.847526\n",
      "test_recall       0.782573\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:50, 30.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time          9.275806\n",
      "score_time        0.313407\n",
      "test_f1           0.740342\n",
      "test_precision    0.841739\n",
      "test_recall       0.660858\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charubaiel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "6it [02:43, 27.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time          10.194652\n",
      "score_time         0.293193\n",
      "test_f1            0.795268\n",
      "test_precision     0.796256\n",
      "test_recall        0.794744\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for n,model in tqdm(enumerate([clf_lr_vec,clf_nb_vec,clf_knn_vec,clf_svc_vec,clf_rf_vec,clf_mlp_vec])):\n",
    "    tmp_pipe = pipeline.make_pipeline(vec_func,model)\n",
    "    models[n] = pd.DataFrame(model_selection.cross_validate(tmp_pipe,data,target,scoring=['f1','precision','recall'],cv=5)).mean()\n",
    "    print(models[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_vec = linear_model.LogisticRegression(max_iter=1000)\n",
    "clf_nb_vec = naive_bayes.BernoulliNB()\n",
    "clf_f_vec = ensemble.RandomForestClassifier(n_estimators=300,max_depth=3)\n",
    "vote_vec = ensemble.VotingClassifier(estimators=[('lr',clf_lr_vec),('nb',clf_nb_vec),('rf',clf_f_vec)],voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_vote_vec = pipeline.make_pipeline(vec_func,vote_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['vote_models'] = pd.DataFrame(model_selection.cross_validate(pipe_vote_vec,data,target,scoring=['f1','precision','recall'],cv=5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function get_sentence_vecror at 0x7f92b5df8af0>)),\n",
       "                ('votingclassifier',\n",
       "                 VotingClassifier(estimators=[('lr',\n",
       "                                               LogisticRegression(max_iter=1000)),\n",
       "                                              ('nb', BernoulliNB()),\n",
       "                                              ('rf',\n",
       "                                               RandomForestClassifier(max_depth=3,\n",
       "                                                                      n_estimators=300))],\n",
       "                                  voting='soft'))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_vote_vec.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>normalize</th>\n",
       "      <th>features</th>\n",
       "      <th>sample_vec</th>\n",
       "      <th>idf_features</th>\n",
       "      <th>vote_models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.242109</td>\n",
       "      <td>0.168174</td>\n",
       "      <td>0.618072</td>\n",
       "      <td>1.262928</td>\n",
       "      <td>6.238955</td>\n",
       "      <td>8.454006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.039719</td>\n",
       "      <td>0.025518</td>\n",
       "      <td>0.076721</td>\n",
       "      <td>0.278110</td>\n",
       "      <td>0.583107</td>\n",
       "      <td>0.327737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.670582</td>\n",
       "      <td>0.704610</td>\n",
       "      <td>0.708455</td>\n",
       "      <td>0.800196</td>\n",
       "      <td>0.792038</td>\n",
       "      <td>0.733347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.836171</td>\n",
       "      <td>0.877150</td>\n",
       "      <td>0.875075</td>\n",
       "      <td>0.832169</td>\n",
       "      <td>0.897874</td>\n",
       "      <td>0.765736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.559889</td>\n",
       "      <td>0.588935</td>\n",
       "      <td>0.595297</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.708714</td>\n",
       "      <td>0.704011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                baseline  normalize  features  sample_vec  idf_features  \\\n",
       "fit_time        0.242109   0.168174  0.618072    1.262928      6.238955   \n",
       "score_time      0.039719   0.025518  0.076721    0.278110      0.583107   \n",
       "test_f1         0.670582   0.704610  0.708455    0.800196      0.792038   \n",
       "test_precision  0.836171   0.877150  0.875075    0.832169      0.897874   \n",
       "test_recall     0.559889   0.588935  0.595297    0.770678      0.708714   \n",
       "\n",
       "                vote_models  \n",
       "fit_time           8.454006  \n",
       "score_time         0.327737  \n",
       "test_f1            0.733347  \n",
       "test_precision     0.765736  \n",
       "test_recall        0.704011  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blend results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(estimators,x,func=np.mean):\n",
    "    probs = []\n",
    "    for i in estimators:\n",
    "        probs.append(i.predict_proba(x)[:,1])\n",
    "    return np.apply_over_axes(func,np.array(probs),axes=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val_data = val_data.copy()\n",
    "val_data = pd.Series(normalizer(' жожо '.join(val_data)).split('жожо'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/charubaiel/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "eval_data = defaultdict(list)\n",
    "for model in [pipe_norm,pipe_fe,pipe_idf_fe,pipe_vec,pipe_vote_vec]:\n",
    "    eval_data['f1'].append(metrics.f1_score(val_target,model.predict(val_data)))\n",
    "    eval_data['recall'].append(metrics.recall_score(val_target,model.predict(val_data)))\n",
    "    eval_data['precision'].append(metrics.precision_score(val_target,model.predict(val_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data['f1'].append(metrics.f1_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data).round()))\n",
    "eval_data['recall'].append(metrics.recall_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data).round()))\n",
    "eval_data['precision'].append(metrics.precision_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data).round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data['f1'].append(metrics.f1_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data,func=np.max).round()))\n",
    "eval_data['recall'].append(metrics.recall_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data,func=np.max).round()))\n",
    "eval_data['precision'].append(metrics.precision_score(val_target,voting([pipe_vec,pipe_idf_fe],val_data,func=np.max).round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blend_max</th>\n",
       "      <td>0.843621</td>\n",
       "      <td>0.846408</td>\n",
       "      <td>0.840853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blend_mean</th>\n",
       "      <td>0.818870</td>\n",
       "      <td>0.759703</td>\n",
       "      <td>0.888031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idf_df</th>\n",
       "      <td>0.805929</td>\n",
       "      <td>0.718415</td>\n",
       "      <td>0.917722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vec</th>\n",
       "      <td>0.800348</td>\n",
       "      <td>0.759703</td>\n",
       "      <td>0.845588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fe</th>\n",
       "      <td>0.731827</td>\n",
       "      <td>0.615194</td>\n",
       "      <td>0.903030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm</th>\n",
       "      <td>0.731731</td>\n",
       "      <td>0.616020</td>\n",
       "      <td>0.900966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote_vec</th>\n",
       "      <td>0.715929</td>\n",
       "      <td>0.668043</td>\n",
       "      <td>0.771211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  f1    recall  precision\n",
       "blend_max   0.843621  0.846408   0.840853\n",
       "blend_mean  0.818870  0.759703   0.888031\n",
       "idf_df      0.805929  0.718415   0.917722\n",
       "vec         0.800348  0.759703   0.845588\n",
       "fe          0.731827  0.615194   0.903030\n",
       "norm        0.731731  0.616020   0.900966\n",
       "vote_vec    0.715929  0.668043   0.771211"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(eval_data,index=['norm','fe','idf_df','vec','vote_vec','blend_mean','blend_max']).sort_values(by='f1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7801a1fce19b4dbca8b7bce4059e552648312323ed9d108616a9100a6d7a4a9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
