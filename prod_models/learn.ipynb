{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/charubaiel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import lightgbm as lgbm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download(\"stopwords\")\n",
    "plt.style.use('ggplot')\n",
    "import joblib\n",
    "from navec import Navec\n",
    "\n",
    "nav = Navec.load('../models/emb_navec.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_neg = pd.read_csv('../data/negative.csv',sep=';',header=None,usecols=[3])\n",
    "twitter_pos = pd.read_csv('../data/positive.csv',sep=';',header=None,usecols=[3])\n",
    "vk_all = pd.read_csv('../data/labeled.csv')\n",
    "ttl_toxic = vk_all.append(twitter_pos.rename(columns={3:'comment'}).sample(5000)).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,target = ttl_toxic['comment'],ttl_toxic['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "stopwords = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer (text):\n",
    "    words_only = re.sub('[^А-я]+',' ',text.lower())\n",
    "    doc = Doc(words_only)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    clean_text = []\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "        if (token.lemma not in stopwords) & (len(set(token.lemma))>1):\n",
    "            clean_text.append(token.lemma)\n",
    "            \n",
    "    return ' '.join(clean_text)\n",
    "    \n",
    "def get_sentence_vector(sentence_list):\n",
    "    vectors = []\n",
    "    for sentence in sentence_list:\n",
    "        sent_vec = []\n",
    "        for i in sentence.split():\n",
    "            if i in nav:\n",
    "                sent_vec.append(nav[i])\n",
    "            else:\n",
    "                sent_vec.append(nav['<unk>'])\n",
    "        if sentence.strip() == '':\n",
    "            sent_vec = [nav['<unk>']]\n",
    "        vectors.append(np.mean(sent_vec,axis=0))\n",
    "    return np.vstack(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(normalizer(' жожо '.join(data)).split('жожо'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3] END alpha=0.01, hidden_layer_sizes=(100, 3);, score=0.707 total time=  22.1s\n",
      "[CV 2/3] END alpha=0.01, hidden_layer_sizes=(100, 3);, score=0.704 total time=   7.5s\n",
      "[CV 2/3] END alpha=0.060000000000000005, hidden_layer_sizes=(100, 1);, score=0.000 total time=  33.1s\n",
      "[CV 3/3] END alpha=0.01, hidden_layer_sizes=(100, 3);, score=0.551 total time=  11.6s\n",
      "[CV 1/3] END alpha=0.060000000000000005, hidden_layer_sizes=(300, 5);, score=0.722 total time=  40.2s\n",
      "[CV 2/3] END alpha=0.060000000000000005, hidden_layer_sizes=(300, 5);, score=0.737 total time=  58.1s\n",
      "[CV 1/3] END alpha=0.01, hidden_layer_sizes=(300, 5);, score=0.725 total time=  10.1s\n",
      "[CV 2/3] END alpha=0.01, hidden_layer_sizes=(300, 5);, score=0.722 total time=   9.4s\n",
      "[CV 1/3] END alpha=0.060000000000000005, hidden_layer_sizes=(100, 1);, score=0.710 total time= 2.1min\n",
      "[CV 3/3] END alpha=0.060000000000000005, hidden_layer_sizes=(300, 5);, score=0.557 total time=  54.2s\n",
      "[CV 3/3] END alpha=0.01, hidden_layer_sizes=(300, 5);, score=0.562 total time=  13.9s\n",
      "[CV 3/3] END alpha=0.060000000000000005, hidden_layer_sizes=(100, 1);, score=0.574 total time= 2.6min\n",
      "[CV 1/3] END alpha=0.060000000000000005, hidden_layer_sizes=(100, 5);, score=0.695 total time= 1.1min\n",
      "[CV 2/3] END alpha=0.060000000000000005, hidden_layer_sizes=(100, 5);, score=0.705 total time=   8.3s\n",
      "[CV 3/3] END alpha=0.060000000000000005, hidden_layer_sizes=(100, 5);, score=0.553 total time=   9.7s\n",
      "[CV 1/3] END alpha=0.01, hidden_layer_sizes=(100, 5);, score=0.716 total time=   5.4s\n",
      "[CV 2/3] END alpha=0.01, hidden_layer_sizes=(100, 5);, score=0.708 total time=   6.0s\n",
      "[CV 3/3] END alpha=0.01, hidden_layer_sizes=(100, 5);, score=0.540 total time=   6.7s\n",
      "[CV 1/3] END alpha=0.01, hidden_layer_sizes=(100, 1);, score=0.000 total time=  29.6s\n",
      "[CV 2/3] END alpha=0.01, hidden_layer_sizes=(100, 1);, score=0.729 total time=   9.5s\n",
      "[CV 3/3] END alpha=0.01, hidden_layer_sizes=(100, 1);, score=0.576 total time=  17.6s\n",
      "[CV 1/3] END alpha=0.060000000000000005, hidden_layer_sizes=(100, 3);, score=0.719 total time=  12.2s\n",
      "[CV 2/3] END alpha=0.060000000000000005, hidden_layer_sizes=(100, 3);, score=0.688 total time=  15.5s\n",
      "[CV 3/3] END alpha=0.060000000000000005, hidden_layer_sizes=(100, 3);, score=0.564 total time=  29.1s\n",
      "[CV 1/3] END alpha=0.060000000000000005, hidden_layer_sizes=(300, 3);, score=0.729 total time=  50.1s\n",
      "[CV 1/3] END alpha=0.060000000000000005, hidden_layer_sizes=(300, 1);, score=0.714 total time= 5.6min\n",
      "[CV 3/3] END alpha=0.060000000000000005, hidden_layer_sizes=(300, 1);, score=0.570 total time= 6.4min\n",
      "[CV 2/3] END alpha=0.060000000000000005, hidden_layer_sizes=(300, 1);, score=0.721 total time= 6.7min\n",
      "[CV 3/3] END alpha=0.060000000000000005, hidden_layer_sizes=(300, 3);, score=0.558 total time= 1.7min\n",
      "[CV 2/3] END alpha=0.060000000000000005, hidden_layer_sizes=(300, 3);, score=0.722 total time= 2.5min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=MLPClassifier(hidden_layer_sizes=(100, 3),\n",
       "                                           learning_rate='adaptive',\n",
       "                                           max_iter=500),\n",
       "                   n_jobs=4,\n",
       "                   param_distributions={'alpha': array([0.01, 0.06]),\n",
       "                                        'hidden_layer_sizes': [(100, 1),\n",
       "                                                               (100, 3),\n",
       "                                                               (100, 5),\n",
       "                                                               (300, 1),\n",
       "                                                               (300, 3),\n",
       "                                                               (300, 5)]},\n",
       "                   scoring='f1', verbose=5)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_vec = neural_network.MLPClassifier(hidden_layer_sizes=(100,3),learning_rate='adaptive')\n",
    "prms_vc = {'hidden_layer_sizes':[(100,1),(100,3),(100,5),(300,1),(300,3),(300,5)],\n",
    "            'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    "            'alpha':np.arange(0.001,0.1,0.05)}\n",
    "\n",
    "rs_vc = model_selection.RandomizedSearchCV(clf_vec,prms_vc,cv=3,scoring='f1',n_iter=10,n_jobs=4,verbose=5)\n",
    "\n",
    "rs_vc.fit(get_sentence_vector(data),target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_params_idx = pd.DataFrame(rs_vc.cv_results_).sort_values(by='mean_test_score',ascending=False).apply(lambda x: x['mean_test_score'] / x['mean_score_time'],axis=1).sort_values().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 'adaptive', 'hidden_layer_sizes': (100, 1), 'alpha': 0.001}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params_mlp = pd.DataFrame(rs_vc.cv_results_).loc[top_params_idx]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "[CV] END  f1: (test=0.669) precision: (test=0.637) recall: (test=0.704) total time=  16.9s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.763) precision: (test=0.788) recall: (test=0.740) total time=  14.0s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   30.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.745) precision: (test=0.834) recall: (test=0.674) total time=  10.6s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   41.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.558) precision: (test=0.637) recall: (test=0.497) total time=  12.5s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   54.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.628) precision: (test=0.617) recall: (test=0.638) total time=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.001, hidden_layer_sizes=(300, 5))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "clf_vec = neural_network.MLPClassifier(**opt_params_mlp)\n",
    "\n",
    "scores['vec'] = pd.DataFrame(model_selection.cross_validate(clf_vec,get_sentence_vector(data),target,scoring=['f1','precision','recall'],cv=5,verbose=10)).mean()\n",
    "\n",
    "clf_vec.fit(get_sentence_vector(data),target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = feature_extraction.text.TfidfVectorizer()\n",
    "word_vectorizer.fit(data)\n",
    "char_vectorizer = feature_extraction.text.TfidfVectorizer(\n",
    "    min_df=3,\n",
    "    sublinear_tf=True,\n",
    "    analyzer='char',\n",
    "    ngram_range=(2,4))\n",
    "char_vectorizer.fit(data)\n",
    "\n",
    "idf_fu = pipeline.FeatureUnion([('idf_w',word_vectorizer),('idf_c',char_vectorizer)])\n",
    "clf_2idf = lgbm.LGBMClassifier(n_estimators=500,class_weight = target.value_counts(normalize=True).to_dict())\n",
    "pipe_idf_fe = pipeline.Pipeline([('idf',idf_fu),('clf',clf_2idf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('idf',\n",
       "                 FeatureUnion(transformer_list=[('idf_w', TfidfVectorizer()),\n",
       "                                                ('idf_c',\n",
       "                                                 TfidfVectorizer(analyzer='char',\n",
       "                                                                 min_df=3,\n",
       "                                                                 ngram_range=(2,\n",
       "                                                                              4),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                ('clf',\n",
       "                 LGBMClassifier(class_weight={0.0: 0.7513908922316093,\n",
       "                                              1.0: 0.24860910776839068},\n",
       "                                n_estimators=500))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_idf_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prms_vc_idf = {'clf__n_estimators':np.arange(100,2000,200),\n",
    "            'clf__learning_rate':np.arange(0.01,0.2,.05),\n",
    "            'clf__subsample' : [1,.9,.8],\n",
    "            'clf__subsample_freq':[1,2],\n",
    "            'clf__max_depth': [-1,2,4,6,9,12,15],\n",
    "            'clf__num_leaves': [5,10,20,30,50,80]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3] END clf__learning_rate=0.060000000000000005, clf__max_depth=6, clf__n_estimators=500, clf__num_leaves=10, clf__subsample=1, clf__subsample_freq=1;, score=0.911 total time= 1.0min\n",
      "[CV 2/3] END clf__learning_rate=0.060000000000000005, clf__max_depth=6, clf__n_estimators=500, clf__num_leaves=10, clf__subsample=1, clf__subsample_freq=1;, score=0.933 total time= 1.1min\n",
      "[CV 3/3] END clf__learning_rate=0.060000000000000005, clf__max_depth=6, clf__n_estimators=500, clf__num_leaves=10, clf__subsample=1, clf__subsample_freq=1;, score=0.818 total time= 1.3min\n",
      "[CV 1/3] END clf__learning_rate=0.060000000000000005, clf__max_depth=-1, clf__n_estimators=1300, clf__num_leaves=5, clf__subsample=1, clf__subsample_freq=2;, score=0.915 total time= 1.5min\n",
      "[CV 1/3] END clf__learning_rate=0.11, clf__max_depth=6, clf__n_estimators=1100, clf__num_leaves=30, clf__subsample=0.8, clf__subsample_freq=2;, score=0.912 total time= 2.8min\n",
      "[CV 2/3] END clf__learning_rate=0.11, clf__max_depth=6, clf__n_estimators=1100, clf__num_leaves=30, clf__subsample=0.8, clf__subsample_freq=2;, score=0.929 total time= 2.9min\n",
      "[CV 2/3] END clf__learning_rate=0.060000000000000005, clf__max_depth=-1, clf__n_estimators=1300, clf__num_leaves=5, clf__subsample=1, clf__subsample_freq=2;, score=0.938 total time= 1.8min\n",
      "[CV 3/3] END clf__learning_rate=0.11, clf__max_depth=6, clf__n_estimators=1100, clf__num_leaves=30, clf__subsample=0.8, clf__subsample_freq=2;, score=0.815 total time= 3.6min\n",
      "[CV 3/3] END clf__learning_rate=0.060000000000000005, clf__max_depth=-1, clf__n_estimators=1300, clf__num_leaves=5, clf__subsample=1, clf__subsample_freq=2;, score=0.824 total time= 2.3min\n",
      "[CV 1/3] END clf__learning_rate=0.11, clf__max_depth=2, clf__n_estimators=300, clf__num_leaves=30, clf__subsample=0.9, clf__subsample_freq=2;, score=0.899 total time=  45.1s\n",
      "[CV 1/3] END clf__learning_rate=0.16000000000000003, clf__max_depth=15, clf__n_estimators=1100, clf__num_leaves=10, clf__subsample=0.8, clf__subsample_freq=1;, score=0.910 total time= 2.1min\n",
      "[CV 2/3] END clf__learning_rate=0.11, clf__max_depth=2, clf__n_estimators=300, clf__num_leaves=30, clf__subsample=0.9, clf__subsample_freq=2;, score=0.913 total time=  47.0s\n",
      "[CV 2/3] END clf__learning_rate=0.16000000000000003, clf__max_depth=15, clf__n_estimators=1100, clf__num_leaves=10, clf__subsample=0.8, clf__subsample_freq=1;, score=0.925 total time= 2.1min\n",
      "[CV 3/3] END clf__learning_rate=0.11, clf__max_depth=2, clf__n_estimators=300, clf__num_leaves=30, clf__subsample=0.9, clf__subsample_freq=2;, score=0.798 total time=  56.1s\n",
      "[CV 3/3] END clf__learning_rate=0.16000000000000003, clf__max_depth=15, clf__n_estimators=1100, clf__num_leaves=10, clf__subsample=0.8, clf__subsample_freq=1;, score=0.809 total time= 2.6min\n",
      "[CV 1/3] END clf__learning_rate=0.01, clf__max_depth=-1, clf__n_estimators=500, clf__num_leaves=20, clf__subsample=1, clf__subsample_freq=2;, score=0.899 total time= 1.9min\n",
      "[CV 2/3] END clf__learning_rate=0.01, clf__max_depth=-1, clf__n_estimators=500, clf__num_leaves=20, clf__subsample=1, clf__subsample_freq=2;, score=0.918 total time= 2.0min\n",
      "[CV 1/3] END clf__learning_rate=0.11, clf__max_depth=12, clf__n_estimators=1700, clf__num_leaves=80, clf__subsample=0.8, clf__subsample_freq=2;, score=0.907 total time= 6.0min\n",
      "[CV 2/3] END clf__learning_rate=0.11, clf__max_depth=12, clf__n_estimators=1700, clf__num_leaves=80, clf__subsample=0.8, clf__subsample_freq=2;, score=0.917 total time= 6.0min\n",
      "[CV 1/3] END clf__learning_rate=0.01, clf__max_depth=15, clf__n_estimators=500, clf__num_leaves=5, clf__subsample=1, clf__subsample_freq=1;, score=0.867 total time=  48.1s\n",
      "[CV 2/3] END clf__learning_rate=0.01, clf__max_depth=15, clf__n_estimators=500, clf__num_leaves=5, clf__subsample=1, clf__subsample_freq=1;, score=0.861 total time=  54.7s\n",
      "[CV 3/3] END clf__learning_rate=0.01, clf__max_depth=-1, clf__n_estimators=500, clf__num_leaves=20, clf__subsample=1, clf__subsample_freq=2;, score=0.797 total time= 2.6min\n",
      "[CV 3/3] END clf__learning_rate=0.01, clf__max_depth=15, clf__n_estimators=500, clf__num_leaves=5, clf__subsample=1, clf__subsample_freq=1;, score=0.744 total time= 1.2min\n",
      "[CV 3/3] END clf__learning_rate=0.11, clf__max_depth=12, clf__n_estimators=1700, clf__num_leaves=80, clf__subsample=0.8, clf__subsample_freq=2;, score=0.786 total time= 8.2min\n",
      "[CV 1/3] END clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=1500, clf__num_leaves=30, clf__subsample=0.9, clf__subsample_freq=1;, score=0.910 total time= 4.1min\n",
      "[CV 2/3] END clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=1500, clf__num_leaves=30, clf__subsample=0.9, clf__subsample_freq=1;, score=0.934 total time= 4.2min\n",
      "[CV 1/3] END clf__learning_rate=0.16000000000000003, clf__max_depth=-1, clf__n_estimators=900, clf__num_leaves=50, clf__subsample=1, clf__subsample_freq=2;, score=0.910 total time= 4.8min\n",
      "[CV 3/3] END clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=1500, clf__num_leaves=30, clf__subsample=0.9, clf__subsample_freq=1;, score=0.813 total time= 5.5min\n",
      "[CV 2/3] END clf__learning_rate=0.16000000000000003, clf__max_depth=-1, clf__n_estimators=900, clf__num_leaves=50, clf__subsample=1, clf__subsample_freq=2;, score=0.931 total time= 3.9min\n",
      "[CV 3/3] END clf__learning_rate=0.16000000000000003, clf__max_depth=-1, clf__n_estimators=900, clf__num_leaves=50, clf__subsample=1, clf__subsample_freq=2;, score=0.804 total time= 4.3min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('idf',\n",
       "                                              FeatureUnion(transformer_list=[('idf_w',\n",
       "                                                                              TfidfVectorizer()),\n",
       "                                                                             ('idf_c',\n",
       "                                                                              TfidfVectorizer(analyzer='char',\n",
       "                                                                                              min_df=3,\n",
       "                                                                                              ngram_range=(2,\n",
       "                                                                                                           4),\n",
       "                                                                                              sublinear_tf=True))])),\n",
       "                                             ('clf',\n",
       "                                              LGBMClassifier(class_weight={0.0: 0.7513908922316093,\n",
       "                                                                           1.0: 0.24860910776839068},\n",
       "                                                             n_estimators=500))]),\n",
       "                   n_jobs=4,\n",
       "                   param_distributions={'clf__learning_rate': array([0.01, 0.06, 0.11, 0.16]),\n",
       "                                        'clf__max_depth': [-1, 2, 4, 6, 9, 12,\n",
       "                                                           15],\n",
       "                                        'clf__n_estimators': array([ 100,  300,  500,  700,  900, 1100, 1300, 1500, 1700, 1900]),\n",
       "                                        'clf__num_leaves': [5, 10, 20, 30, 50,\n",
       "                                                            80],\n",
       "                                        'clf__subsample': [1, 0.9, 0.8],\n",
       "                                        'clf__subsample_freq': [1, 2]},\n",
       "                   scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_vc_idf = model_selection.RandomizedSearchCV(pipe_idf_fe,prms_vc_idf,cv=3,scoring='roc_auc',n_iter=10,n_jobs=4,verbose=5)\n",
    "\n",
    "rs_vc_idf.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__subsample_freq': 2,\n",
       " 'clf__subsample': 1,\n",
       " 'clf__num_leaves': 5,\n",
       " 'clf__n_estimators': 1300,\n",
       " 'clf__max_depth': -1,\n",
       " 'clf__learning_rate': 0.060000000000000005}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_vc_idf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_fu = pipeline.FeatureUnion([('idf_w',word_vectorizer),('idf_c',char_vectorizer)])\n",
    "clf_2idf = lgbm.LGBMClassifier(subsample_freq=2,num_leaves=5,n_estimators=1300,learning_rate=0.06,subsample=1,class_weight = target.value_counts(normalize=True).to_dict())\n",
    "pipe_idf_fe = pipeline.Pipeline([('idf',idf_fu),('clf',clf_2idf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  56.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   56.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.0min\n",
      "[CV] END .................................................... total time= 1.0min\n",
      "[CV] END .................................................... total time= 1.1min\n",
      "[CV] END .................................................... total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('idf',\n",
       "                 FeatureUnion(transformer_list=[('idf_w', TfidfVectorizer()),\n",
       "                                                ('idf_c',\n",
       "                                                 TfidfVectorizer(analyzer='char',\n",
       "                                                                 min_df=3,\n",
       "                                                                 ngram_range=(2,\n",
       "                                                                              4),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                ('clf',\n",
       "                 LGBMClassifier(class_weight={0.0: 0.7513908922316093,\n",
       "                                              1.0: 0.24860910776839068},\n",
       "                                learning_rate=0.06, n_estimators=1300,\n",
       "                                num_leaves=5, subsample=1, subsample_freq=2))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['idf_features'] = pd.DataFrame(model_selection.cross_validate(pipe_idf_fe,data,target,scoring=['f1','precision','recall'],cv=5,verbose=10)).mean()\n",
    "pipe_idf_fe.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "[CV] END  f1: (test=0.658) precision: (test=0.714) recall: (test=0.610) total time=  19.6s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.751) precision: (test=0.942) recall: (test=0.624) total time=  22.4s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   42.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.718) precision: (test=0.963) recall: (test=0.572) total time=  20.4s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.381) precision: (test=0.858) recall: (test=0.245) total time=  14.4s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.652) precision: (test=0.697) recall: (test=0.612) total time=  19.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('svc',\n",
       "                              SGDClassifier(class_weight={0.0: 0.7513908922316093,\n",
       "                                                          1.0: 0.24860910776839068},\n",
       "                                            loss='modified_huber',\n",
       "                                            penalty='l1')),\n",
       "                             ('gbm',\n",
       "                              LGBMClassifier(class_weight={0.0: 0.7513908922316093,\n",
       "                                                           1.0: 0.24860910776839068},\n",
       "                                             learning_rate=0.06,\n",
       "                                             n_estimators=1300, num_leaves=5,\n",
       "                                             subsample=1, subsample_freq=2)),\n",
       "                             ('mlp',\n",
       "                              MLPClassifier(hidden_layer_sizes=(300, 1),\n",
       "                                            learning_rate='adaptive',\n",
       "                                            max_iter=1000))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_prior=target.value_counts(normalize=True).values[::-1]\n",
    "\n",
    "clf_svc_vec = linear_model.SGDClassifier(loss='modified_huber',penalty = 'l1',class_weight= target.value_counts(normalize=True).to_dict())\n",
    "clf_rf_vec = lgbm.LGBMClassifier(subsample_freq=2,num_leaves=5,n_estimators=1300,learning_rate=0.06,subsample=1,class_weight= target.value_counts(normalize=True).to_dict())\n",
    "clf_mlp_vec = neural_network.MLPClassifier(hidden_layer_sizes=(300,1),max_iter=1000,learning_rate='adaptive')\n",
    "\n",
    "clf_vote = ensemble.VotingClassifier(estimators=[('svc',clf_svc_vec),('gbm',clf_rf_vec),('mlp',clf_mlp_vec)],voting='soft')\n",
    "\n",
    "scores['vote_models_vec'] = pd.DataFrame(model_selection.cross_validate(clf_vote,get_sentence_vector(data),target,scoring=['f1','precision','recall'],cv=5,verbose=10)).mean()\n",
    "\n",
    "clf_vote.fit(get_sentence_vector(data),target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(sentences,func=np.max):\n",
    "    sentences = [normalizer(txt) for txt in sentences]\n",
    "    probs = []\n",
    "    probs.append(pipe_idf_fe.predict_proba(sentences)[:,1])\n",
    "    probs.append(clf_vote.predict_proba(get_sentence_vector(sentences))[:,1])\n",
    "    probs.append(clf_vec.predict_proba(get_sentence_vector(sentences))[:,1])\n",
    "    return np.apply_over_axes(func,np.array(probs),axes=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.4 ms ± 2.88 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "voting(['какая же ты тварь'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vec</th>\n",
       "      <th>idf_features</th>\n",
       "      <th>vote_models_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>13.424084</td>\n",
       "      <td>62.230302</td>\n",
       "      <td>19.141512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.016642</td>\n",
       "      <td>0.599446</td>\n",
       "      <td>0.110458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.672736</td>\n",
       "      <td>0.633992</td>\n",
       "      <td>0.631755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.702725</td>\n",
       "      <td>0.909813</td>\n",
       "      <td>0.834901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.650631</td>\n",
       "      <td>0.495643</td>\n",
       "      <td>0.532516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      vec  idf_features  vote_models_vec\n",
       "fit_time        13.424084     62.230302        19.141512\n",
       "score_time       0.016642      0.599446         0.110458\n",
       "test_f1          0.672736      0.633992         0.631755\n",
       "test_precision   0.702725      0.909813         0.834901\n",
       "test_recall      0.650631      0.495643         0.532516"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz3 = vk_all.assign(vote_max = voting(vk_all['comment']),\n",
    "                    idf = pipe_idf_fe.predict_proba(vk_all['comment'])[:,1],\n",
    "                    vote = clf_vote.predict_proba(get_sentence_vector(vk_all['comment']))[:,1],\n",
    "                    mlp = clf_vec.predict_proba(get_sentence_vector(vk_all['comment']))[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>mlp</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.461490</td>\n",
       "      <td>0.203650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.079656</td>\n",
       "      <td>0.255204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "mlp         0.0       1.0\n",
       "toxic                    \n",
       "0.0    0.461490  0.203650\n",
       "1.0    0.079656  0.255204"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz3.loc[:,['toxic','mlp']].round().value_counts(normalize=True).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>vote</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.606647</td>\n",
       "      <td>0.058493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.134055</td>\n",
       "      <td>0.200805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "vote        0.0       1.0\n",
       "toxic                    \n",
       "0.0    0.606647  0.058493\n",
       "1.0    0.134055  0.200805"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz3.loc[:,['toxic','vote']].round().value_counts(normalize=True).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idf</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.658965</td>\n",
       "      <td>0.006175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.107272</td>\n",
       "      <td>0.227588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "idf         0.0       1.0\n",
       "toxic                    \n",
       "0.0    0.658965  0.006175\n",
       "1.0    0.107272  0.227588"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz3.loc[:,['toxic','idf']].round().value_counts(normalize=True).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>vote_max</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.661879</td>\n",
       "      <td>0.003261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.330697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "vote_max       0.0       1.0\n",
       "toxic                       \n",
       "0.0       0.661879  0.003261\n",
       "1.0       0.004163  0.330697"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz3.loc[:,['toxic','vote_max']].round().value_counts(normalize=True).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m1.joblib']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe_idf_fe,'m1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m2.joblib']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf_vote,'m2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m3.joblib']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf_vec,'m3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
