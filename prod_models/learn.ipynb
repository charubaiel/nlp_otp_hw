{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/charubaiel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import lightgbm as lgbm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download(\"stopwords\")\n",
    "plt.style.use('ggplot')\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_neg = pd.read_csv('data/negative.csv',sep=';',header=None,usecols=[3])\n",
    "twitter_pos = pd.read_csv('data/positive.csv',sep=';',header=None,usecols=[3])\n",
    "vk_all = pd.read_csv('data/labeled.csv')\n",
    "ttl_toxic = vk_all.append(twitter_pos.rename(columns={3:'comment'}).sample(5000)).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,target = ttl_toxic['comment'],ttl_toxic['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "stopwords = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer (text):\n",
    "    words_only = re.sub('[^А-я]+',' ',text.lower())\n",
    "    doc = Doc(words_only)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    clean_text = []\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "        if (token.lemma not in stopwords) & (len(set(token.lemma))>1):\n",
    "            clean_text.append(token.lemma)\n",
    "            \n",
    "    return ' '.join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(normalizer(' жожо '.join(data)).split('жожо'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "[CV] END  f1: (test=0.662) precision: (test=0.625) recall: (test=0.704) total time=  15.5s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.759) precision: (test=0.825) recall: (test=0.703) total time=  15.0s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   30.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.713) precision: (test=0.802) recall: (test=0.641) total time=  12.9s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   43.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.566) precision: (test=0.609) recall: (test=0.528) total time=  11.1s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   54.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.628) precision: (test=0.585) recall: (test=0.678) total time=  16.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 3))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from navec import Navec\n",
    "\n",
    "nav = Navec.load('models/emb_navec.tar')\n",
    "def get_sentence_vector(sentence_list):\n",
    "    vectors = []\n",
    "    for sentence in sentence_list:\n",
    "        sent_vec = []\n",
    "        for i in sentence.split():\n",
    "            if i in nav:\n",
    "                sent_vec.append(nav[i])\n",
    "            else:\n",
    "                sent_vec.append(nav['<unk>'])\n",
    "        if sentence.strip() == '':\n",
    "            sent_vec = [nav['<unk>']]\n",
    "        vectors.append(np.mean(sent_vec,axis=0))\n",
    "    return np.vstack(vectors)\n",
    "    \n",
    "clf_vec = neural_network.MLPClassifier(hidden_layer_sizes=(100,3))\n",
    "\n",
    "scores['vec'] = pd.DataFrame(model_selection.cross_validate(clf_vec,get_sentence_vector(data),target,scoring=['f1','precision','recall'],cv=5,verbose=10)).mean()\n",
    "\n",
    "clf_vec.fit(get_sentence_vector(data),target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "[CV] END  f1: (test=0.670) precision: (test=0.764) recall: (test=0.596) total time= 1.2min\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.793) precision: (test=0.939) recall: (test=0.686) total time= 1.2min\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.752) precision: (test=0.967) recall: (test=0.616) total time= 1.3min\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  3.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.511) precision: (test=0.784) recall: (test=0.379) total time= 1.5min\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  5.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.703) precision: (test=0.797) recall: (test=0.629) total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  6.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('idf',\n",
       "                 FeatureUnion(transformer_list=[('idf_w', TfidfVectorizer()),\n",
       "                                                ('idf_c',\n",
       "                                                 TfidfVectorizer(analyzer='char',\n",
       "                                                                 min_df=3,\n",
       "                                                                 ngram_range=(2,\n",
       "                                                                              4),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                ('clf',\n",
       "                 LGBMClassifier(class_weight={0.0: 0.7513908922316093,\n",
       "                                              1.0: 0.24860910776839068},\n",
       "                                n_estimators=500))])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer = feature_extraction.text.TfidfVectorizer()\n",
    "word_vectorizer.fit(data)\n",
    "char_vectorizer = feature_extraction.text.TfidfVectorizer(\n",
    "    min_df=3,\n",
    "    sublinear_tf=True,\n",
    "    analyzer='char',\n",
    "    ngram_range=(2,4))\n",
    "char_vectorizer.fit(data)\n",
    "\n",
    "idf_fu = pipeline.FeatureUnion([('idf_w',word_vectorizer),('idf_c',char_vectorizer)])\n",
    "clf_2idf = lgbm.LGBMClassifier(n_estimators=500,class_weight = target.value_counts(normalize=True).to_dict())\n",
    "pipe_idf_fe = pipeline.Pipeline([('idf',idf_fu),('clf',clf_2idf)])\n",
    "scores['idf_features'] = pd.DataFrame(model_selection.cross_validate(pipe_idf_fe,data,target,scoring=['f1','precision','recall'],cv=5,verbose=10)).mean()\n",
    "pipe_idf_fe.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "[CV] END  f1: (test=0.664) precision: (test=0.728) recall: (test=0.610) total time=  24.6s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.737) precision: (test=0.948) recall: (test=0.603) total time=  27.2s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   51.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.715) precision: (test=0.968) recall: (test=0.567) total time=  30.6s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.575) precision: (test=0.671) recall: (test=0.503) total time=  25.7s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1: (test=0.655) precision: (test=0.684) recall: (test=0.628) total time=  26.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('svc',\n",
       "                              SGDClassifier(class_weight={0.0: 0.7513908922316093,\n",
       "                                                          1.0: 0.24860910776839068},\n",
       "                                            loss='modified_huber',\n",
       "                                            penalty='l1')),\n",
       "                             ('gbm',\n",
       "                              LGBMClassifier(class_weight={0.0: 0.7513908922316093,\n",
       "                                                           1.0: 0.24860910776839068},\n",
       "                                             n_estimators=1000,\n",
       "                                             num_leaves=15)),\n",
       "                             ('mlp',\n",
       "                              MLPClassifier(hidden_layer_sizes=(300, 1),\n",
       "                                            learning_rate='adaptive',\n",
       "                                            max_iter=1000))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_prior=target.value_counts(normalize=True).values[::-1]\n",
    "\n",
    "clf_svc_vec = linear_model.SGDClassifier(loss='modified_huber',penalty = 'l1',class_weight= target.value_counts(normalize=True).to_dict())\n",
    "clf_rf_vec = lgbm.LGBMClassifier(n_estimators=1000,num_leaves=15,class_weight= target.value_counts(normalize=True).to_dict())\n",
    "clf_mlp_vec = neural_network.MLPClassifier(hidden_layer_sizes=(300,1),max_iter=1000,learning_rate='adaptive')\n",
    "\n",
    "clf_vote = ensemble.VotingClassifier(estimators=[('svc',clf_svc_vec),('gbm',clf_rf_vec),('mlp',clf_mlp_vec)],voting='soft')\n",
    "\n",
    "scores['vote_models_vec'] = pd.DataFrame(model_selection.cross_validate(clf_vote,get_sentence_vector(data),target,scoring=['f1','precision','recall'],cv=5,verbose=10)).mean()\n",
    "\n",
    "clf_vote.fit(get_sentence_vector(data),target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(sentences,func=np.max):\n",
    "    sentences = [normalizer(txt) for txt in sentences]\n",
    "    probs = []\n",
    "    probs.append(pipe_idf_fe.predict_proba(sentences)[:,1])\n",
    "    probs.append(clf_vote.predict_proba(get_sentence_vector(sentences))[:,1])\n",
    "    probs.append(clf_vec.predict_proba(get_sentence_vector(sentences))[:,1])\n",
    "    return np.apply_over_axes(func,np.array(probs),axes=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.46 ms ± 126 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "voting(['какая же ты тварь'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz3 = vk_all.assign(vote_max = voting(vk_all['comment']),\n",
    "                    idf = pipe_idf_fe.predict_proba(vk_all['comment'])[:,1],\n",
    "                    vote = clf_vote.predict_proba(get_sentence_vector(vk_all['comment']))[:,1],\n",
    "                    mlp = clf_vec.predict_proba(get_sentence_vector(vk_all['comment']))[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>mlp</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.461490</td>\n",
       "      <td>0.203650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.079656</td>\n",
       "      <td>0.255204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "mlp         0.0       1.0\n",
       "toxic                    \n",
       "0.0    0.461490  0.203650\n",
       "1.0    0.079656  0.255204"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz3.loc[:,['toxic','mlp']].round().value_counts(normalize=True).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>vote</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.606647</td>\n",
       "      <td>0.058493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.134055</td>\n",
       "      <td>0.200805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "vote        0.0       1.0\n",
       "toxic                    \n",
       "0.0    0.606647  0.058493\n",
       "1.0    0.134055  0.200805"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz3.loc[:,['toxic','vote']].round().value_counts(normalize=True).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idf</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.658965</td>\n",
       "      <td>0.006175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.107272</td>\n",
       "      <td>0.227588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "idf         0.0       1.0\n",
       "toxic                    \n",
       "0.0    0.658965  0.006175\n",
       "1.0    0.107272  0.227588"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz3.loc[:,['toxic','idf']].round().value_counts(normalize=True).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>vote_max</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.661879</td>\n",
       "      <td>0.003261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.330697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "vote_max       0.0       1.0\n",
       "toxic                       \n",
       "0.0       0.661879  0.003261\n",
       "1.0       0.004163  0.330697"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz3.loc[:,['toxic','vote_max']].round().value_counts(normalize=True).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m1.joblib']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe_idf_fe,'m1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m2.joblib']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf_vote,'m2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m3.joblib']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf_vec,'m3.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
